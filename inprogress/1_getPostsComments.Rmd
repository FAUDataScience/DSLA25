---
title: "getPostsComments"
output: html_document
date: "2024-03-26"
---

for very large files, may need to read in piecemeal.

```{r }
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyjson)
library(jsonlite)
start.time <- Sys.time()
posts <- readLines(
    "r_applyingtocollege_posts.jsonl")[
        1:100000] # for file a1
#        200001:400000] # for file b
#       400001:500000] # for file c
# SELECTION IS done here rather than in a separate step
a1 <- stream_in(textConnection(
     gsub("\\n","", posts))) |> 
     select(author, title, selftext, id, link_flair_text, num_comments,
            permalink, score, subreddit, created_utc) 
write_csv(a1, "applyingposts1.csv")
end.time <- Sys.time()
```


# for smaller files      
```{r}
# posts <- ("r_firstgenstudents_posts.jsonl")
posts2 <- ("r_applyingtocollege_posts1.jsonl")
a <- stream_in(file(posts))
earliesta <-
    as.POSIXct(min(a$created_utc))
latesta <-
    as.POSIXct(max(a$created_utc))
etc. 
# this file is a list - can't write as a csv file
# so save to disk as an rds
# save(c, file = "applyingposts20210118to20211125.rds")
# then open rds file, save appropriate columns, save as dataframe/tibble
```

for comments


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidyjson)
library(jsonlite)
comments <- ("r_ApplyingToCollege_comments.jsonl")
a <- stream_in(file(comments))
# fails a <- fromJSON(file(comments))
# fails a <- read_json("r_firstgenstudents_comments.jsonl")
comments <- a %>% 
    select(author, body, created_utc, id, score, subreddit) %>% 
    as_tibble %>% 
    write_csv("ApplyingToCollegeComments.csv")
```

some data cleaning may be appropriate here, but the file should be readable by the LIWC software
```{r}
```


