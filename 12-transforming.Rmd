---
title: "12-Dplyr data"
author: "Kevin Lanning"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---
# transforming data

Once you have your data, you will almost invariably need to transform it - to sort it, to select observations or variables from it, to create new variables, to partition it into groups, or to summarize it. In R, there is a general purpose tool (ok, package) that exists for this called dplyr ("d-plier").  **Play with the various dplyr functions. Experiment. You will not break the internet**

![Fig 12.1 - pliers to play with](pliers.png)

Dplyr is a core part of the tidyverse and hence is loaded automatically when you load the tidyverse ensemble of libraries:

```{r}
library(tidyverse)
```

The versatility of dplyr is demonstrated in Chapter 5 of R4DS, which shows how to do many basic, and some not so basic, operations on your data.  Read it closely if you haven't already done so.

## from data on the web to data in R

Let's consider a dataset consisting of 10,000 songs (observations) and 35 measures (variables including artist). The first step here (and for your class project and the data science challenge) will be to get the data into R. How do you this?

> Method 1: Download the file to your computer as a csv file. Some advantages of this include  (a) it will allow the code to run even if the website changes or disappears, (b) in the likely event that I will run the code several times, it is faster to get data from my own machine than from the cloud, and (c) if there are any anomalies in the data I can look at them locally (e.g., in Notepad++). If you use this approach, make sure that you know where your data is on your computer.  The easiest way to do this is to work with an R project. Within R studio, create a new R project (or use an existing one). Move the csv file into this directory, so that data, code, and results will all be in the same place.
>
> Method 2:  Import the data from the cloud directly into R. You can do this either by specifying the musicURL separately (Method 2a) or call it directly within the read_csv statement (2b).  Here, too, I would encourage you to set up and work within a project.

```{r echo=TRUE, results="hide", message=FALSE}
library(tidyverse)
### Method 1
# music1 <- read_csv("music.csv") 
### Method 2a
musicURL <- 
  "https://think.cs.vt.edu/corgis/datasets/csv/music/music.csv?forcedownload=1"
music1 <- read_csv(musicURL)
### Method 2b
# music1 <- read_csv(
#  "https://think.cs.vt.edu/corgis/csv/music/music.csv?forcedownload=1"
#  )
```

What can you do with the data in its existing form? What questions do you wish you could ask about these songs, artists, and the places they come from?

When I first ran this code in 2018, the variables included states and countries.  The current dataset doesn't have these, but it does have longitude and latitude. 
Once the data are in R, experiment with it. Here's what we did in class.

This code worked in 2019, but in 2020 the music data is coded only in terms of latitude and longitude. To get state data from this, reverse  geocoding is needed. A Google search turned up the following. Note that it requires two additional packages
```{r}
library(maps)
library(maptools)
# source is https://github.com/abresler

# The single argument to this function, pointsDF, is a data.frame in which:
#   - column 1 contains the longitude in degrees (negative in the US)
#   - column 2 contains the latitude in degrees
latlong2state <- function(pointsDF) {
    # Prepare SpatialPolygons object with one SpatialPolygon
    # per state (plus DC, minus HI & AK)
    states <- map('state', fill=TRUE, col="transparent", plot=FALSE)
    IDs <- sapply(strsplit(states$names, ":"), function(x) x[1])
    states_sp <- map2SpatialPolygons(states, IDs=IDs,
                     proj4string=CRS("+proj=longlat +datum=WGS84"))

    # Convert pointsDF to a SpatialPoints object 
    pointsSP <- SpatialPoints(pointsDF, 
                    proj4string=CRS("+proj=longlat +datum=WGS84"))

    # Use 'over' to get _indices_ of the Polygons object containing each point 
    indices <- over(pointsSP, states_sp)

    # Return the state names of the Polygons object containing each point
    stateNames <- sapply(states_sp@polygons, function(x) x@ID)
    stateNames[indices]
}
latlong <- music1 %>% 
  select (artist.longitude, 
              artist.latitude)
USartists <- music1 %>% 
  mutate(state = 
            latlong2state(latlong)) %>% 
  drop_na(state)
```

So - now you have a list of songs and artists and some measures of "hotttness." Can you use things like filter, arrange, and select to do something interesting with these data?

## babynames

We also explored the babynames library in R. You'll need to install this on your computer if you haven't already done so to. Play with it, and now that you have mastered dplyr, use mutate to create some new measures that tell an interesting story about these data. 

```{r}
library(babynames)
str(babynames)
```

## exercises

1) make progress on your class project. You will be presenting this two weeks from today.

2) Work with the babynames data, using the tools of dplyr. What names are most androgynous (are equally popular among males and females in a given year)? Contribute to a discussion about how to do this on Slack, building on the work of your classmates.  

