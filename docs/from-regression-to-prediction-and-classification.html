<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>18 From regression to prediction and classification | Data science for the liberal arts</title>
  <meta name="description" content="Test">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="18 From regression to prediction and classification | Data science for the liberal arts" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/diffprop_cloud_250_sm.png" />
  <meta property="og:description" content="Test" />
  <meta name="github-repo" content="kevinlanning/DataSciLibArts" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="18 From regression to prediction and classification | Data science for the liberal arts" />
  
  <meta name="twitter:description" content="Test" />
  <meta name="twitter:image" content="images/diffprop_cloud_250_sm.png" />

<meta name="author" content="Kevin Lanning">


<meta name="date" content="2019-03-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression-and-modeling.html">
<link rel="next" href="another-approach-to-prediction-k-nearest-neighbor.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science for the Liberal Arts</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="an-invitation.html"><a href="an-invitation.html"><i class="fa fa-check"></i>an invitation</a><ul>
<li class="chapter" data-level="" data-path="an-invitation.html"><a href="an-invitation.html#what-will-be-in-the-class"><i class="fa fa-check"></i>what will be in the class?</a></li>
<li class="chapter" data-level="" data-path="an-invitation.html"><a href="an-invitation.html#should-you-enroll"><i class="fa fa-check"></i>should you enroll?</a></li>
</ul></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html"><i class="fa fa-check"></i><b>1</b> data science for the liberal arts</a><ul>
<li class="chapter" data-level="1.1" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#type-c-data-science-data-science-for-the-liberal-arts"><i class="fa fa-check"></i><b>1.1</b> type C data science = data science for the liberal arts</a></li>
<li class="chapter" data-level="1.2" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#the-incompleteness-of-the-data-science-venn-diagram"><i class="fa fa-check"></i><b>1.2</b> the incompleteness of the data science Venn diagram</a></li>
<li class="chapter" data-level="1.3" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#a-dimension-of-depth"><i class="fa fa-check"></i><b>1.3</b> a dimension of depth</a></li>
<li class="chapter" data-level="1.4" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#google-and-the-liberal-arts"><i class="fa fa-check"></i><b>1.4</b> Google and the liberal arts</a></li>
<li class="chapter" data-level="1.5" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#data-sci-and-tmi"><i class="fa fa-check"></i><b>1.5</b> data sci and TMI</a></li>
<li class="chapter" data-level="1.6" data-path="data-science-for-the-liberal-arts.html"><a href="data-science-for-the-liberal-arts.html#discussion-what-will-you-do-with-data-science"><i class="fa fa-check"></i><b>1.6</b> discussion: what will you do with data science?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>2</b> getting started</a><ul>
<li class="chapter" data-level="2.1" data-path="getting-started.html"><a href="getting-started.html#are-you-already-a-programmer-and-statistician"><i class="fa fa-check"></i><b>2.1</b> are you already a programmer and statistician?</a></li>
<li class="chapter" data-level="2.2" data-path="getting-started.html"><a href="getting-started.html#setting-up-your-machine-some-basic-tools"><i class="fa fa-check"></i><b>2.2</b> setting up your machine: some basic tools</a></li>
<li class="chapter" data-level="2.3" data-path="getting-started.html"><a href="getting-started.html#discussion-who-deserves-a-good-grade"><i class="fa fa-check"></i><b>2.3</b> discussion: who deserves a good grade?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html"><i class="fa fa-check"></i><b>3</b> an introduction to R</a><ul>
<li class="chapter" data-level="3.1" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html#some-other-things-that-r-stands-for"><i class="fa fa-check"></i><b>3.1</b> some other things that R stands for</a></li>
<li class="chapter" data-level="3.2" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html#a-few-characteristics-of-r"><i class="fa fa-check"></i><b>3.2</b> a few characteristics of R</a></li>
<li class="chapter" data-level="3.3" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html#finding-help"><i class="fa fa-check"></i><b>3.3</b> finding help</a></li>
<li class="chapter" data-level="3.4" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html#wickham-and-r-for-data-science"><i class="fa fa-check"></i><b>3.4</b> Wickham and R for Data Science</a></li>
<li class="chapter" data-level="3.5" data-path="an-introduction-to-r.html"><a href="an-introduction-to-r.html#discussion-is-open-source-software-secure"><i class="fa fa-check"></i><b>3.5</b> discussion: is open-source software secure?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html"><i class="fa fa-check"></i><b>4</b> now draw the rest of the owl</a><ul>
<li class="chapter" data-level="4.1" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#carmichael"><i class="fa fa-check"></i><b>4.1</b> Carmichael</a></li>
<li class="chapter" data-level="4.2" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#datacamp"><i class="fa fa-check"></i><b>4.2</b> DataCamp</a></li>
<li class="chapter" data-level="4.3" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#swirl-swirlstats"><i class="fa fa-check"></i><b>4.3</b> Swirl (Swirlstats)</a></li>
<li class="chapter" data-level="4.4" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#peng-text-and-videos"><i class="fa fa-check"></i><b>4.4</b> Peng text and videos</a></li>
<li class="chapter" data-level="4.5" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#something-else"><i class="fa fa-check"></i><b>4.5</b> Something else</a></li>
<li class="chapter" data-level="4.6" data-path="now-draw-the-rest-of-the-owl.html"><a href="now-draw-the-rest-of-the-owl.html#exercise"><i class="fa fa-check"></i><b>4.6</b> Exercise</a></li>
</ul></li>
<li class="part"><span><b>II Part II Towards data literacy</b></span></li>
<li class="chapter" data-level="5" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html"><i class="fa fa-check"></i><b>5</b> Principles of data visualization</a><ul>
<li class="chapter" data-level="5.1" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#some-opening-thoughts"><i class="fa fa-check"></i><b>5.1</b> Some opening thoughts</a></li>
<li class="chapter" data-level="5.2" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#some-early-graphs"><i class="fa fa-check"></i><b>5.2</b> Some early graphs</a></li>
<li class="chapter" data-level="5.3" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#tukey-and-eda"><i class="fa fa-check"></i><b>5.3</b> Tukey and EDA</a></li>
<li class="chapter" data-level="5.4" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#approaches-to-graphs"><i class="fa fa-check"></i><b>5.4</b> Approaches to graphs</a></li>
<li class="chapter" data-level="5.5" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#tufte-first-principles"><i class="fa fa-check"></i><b>5.5</b> Tufte: First principles</a><ul>
<li class="chapter" data-level="5.5.1" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#the-cost-of-poor-design-i-space-shuttle-challenger"><i class="fa fa-check"></i><b>5.5.1</b> The cost of poor design I: Space Shuttle Challenger</a></li>
<li class="chapter" data-level="5.5.2" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#the-cost-of-poor-design-ii-an-uninformed-or-misinformed-world."><i class="fa fa-check"></i><b>5.5.2</b> The cost of poor design II: An uninformed or misinformed world.</a></li>
<li class="chapter" data-level="5.5.3" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#should-graphs-begin-with-psychological-theory"><i class="fa fa-check"></i><b>5.5.3</b> Should graphs begin with psychological theory?</a></li>
<li class="chapter" data-level="5.5.4" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#the-power-of-animation"><i class="fa fa-check"></i><b>5.5.4</b> The power of animation</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#telling-the-truth-when-the-truth-is-unclear"><i class="fa fa-check"></i><b>5.6</b> Telling the truth, when the truth is unclear</a><ul>
<li class="chapter" data-level="5.6.1" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#animated-approaches"><i class="fa fa-check"></i><b>5.6.1</b> Animated approaches</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#a-supplement-code-for-asymmetrical-eulervenn-diagrams"><i class="fa fa-check"></i><b>5.7</b> a supplement: Code for Asymmetrical Euler/Venn diagrams</a><ul>
<li class="chapter" data-level="5.7.1" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#setup"><i class="fa fa-check"></i><b>5.7.1</b> setup</a></li>
<li class="chapter" data-level="5.7.2" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#cpi--cq"><i class="fa fa-check"></i><b>5.7.2</b> CPI- CQ</a></li>
<li class="chapter" data-level="5.7.3" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#scholarly-communities"><i class="fa fa-check"></i><b>5.7.3</b> scholarly communities</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="principles-of-data-visualization.html"><a href="principles-of-data-visualization.html#further-reading-and-resources"><i class="fa fa-check"></i><b>5.8</b> further reading and resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html"><i class="fa fa-check"></i><b>6</b> visualization in R with ggplot</a><ul>
<li class="chapter" data-level="6.1" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html#picture-words-numbers"><i class="fa fa-check"></i><b>6.1</b> picture &gt; (words, numbers)?</a></li>
<li class="chapter" data-level="6.2" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html#your-ggplots"><i class="fa fa-check"></i><b>6.2</b> your ggplots</a></li>
<li class="chapter" data-level="6.3" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html#facets---displaying-the-anscombe-data"><i class="fa fa-check"></i><b>6.3</b> facets - displaying the Anscombe data</a></li>
<li class="chapter" data-level="6.4" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html#exploring-more-data"><i class="fa fa-check"></i><b>6.4</b> exploring more data</a></li>
<li class="chapter" data-level="6.5" data-path="visualization-in-r-with-ggplot.html"><a href="visualization-in-r-with-ggplot.html#r-is-the-bomb"><i class="fa fa-check"></i><b>6.5</b> R is the bomb</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html"><i class="fa fa-check"></i><b>7</b> on probability and statistics</a><ul>
<li class="chapter" data-level="7.1" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#on-probability"><i class="fa fa-check"></i><b>7.1</b> on probability</a></li>
<li class="chapter" data-level="7.2" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#the-rules-of-probability"><i class="fa fa-check"></i><b>7.2</b> the rules of probability</a><ul>
<li class="chapter" data-level="7.2.1" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#keeping-conditional-probabilities-straight"><i class="fa fa-check"></i><b>7.2.1</b> keeping conditional probabilities straight</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#continuous-probability-distributions"><i class="fa fa-check"></i><b>7.3</b> continuous probability distributions</a></li>
<li class="chapter" data-level="7.4" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#the-most-dangerous-equation"><i class="fa fa-check"></i><b>7.4</b> the most dangerous equation</a></li>
<li class="chapter" data-level="7.5" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#appendix-notes-on-discrete-probability"><i class="fa fa-check"></i><b>7.5</b> appendix: notes on discrete probability</a></li>
<li class="chapter" data-level="7.6" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#discrete-probability-see-attribution-in-7.5"><i class="fa fa-check"></i><b>7.6</b> Discrete Probability (see attribution in 7.5)</a><ul>
<li class="chapter" data-level="7.6.1" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#relative-frequency"><i class="fa fa-check"></i><b>7.6.1</b> Relative Frequency</a></li>
<li class="chapter" data-level="7.6.2" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#notation"><i class="fa fa-check"></i><b>7.6.2</b> Notation</a></li>
<li class="chapter" data-level="7.6.3" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#monte-carlo-simulations"><i class="fa fa-check"></i><b>7.6.3</b> Monte Carlo Simulations</a></li>
<li class="chapter" data-level="7.6.4" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#with-and-without-replacement"><i class="fa fa-check"></i><b>7.6.4</b> With and without replacement</a></li>
<li class="chapter" data-level="7.6.5" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#probability-distributions"><i class="fa fa-check"></i><b>7.6.5</b> Probability Distributions</a></li>
<li class="chapter" data-level="7.6.6" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#independence"><i class="fa fa-check"></i><b>7.6.6</b> Independence</a></li>
<li class="chapter" data-level="7.6.7" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#conditional-probabilities"><i class="fa fa-check"></i><b>7.6.7</b> Conditional Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#multiplication-rule-see-attribution-in-7.5"><i class="fa fa-check"></i><b>7.7</b> Multiplication rule (see attribution in 7.5)</a><ul>
<li class="chapter" data-level="7.7.1" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#combinations-and-permutations"><i class="fa fa-check"></i><b>7.7.1</b> Combinations and Permutations</a></li>
<li class="chapter" data-level="7.7.2" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#birthday-problem"><i class="fa fa-check"></i><b>7.7.2</b> Birthday Problem</a></li>
<li class="chapter" data-level="7.7.3" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#sapply-a-better-way-to-do-for-loops"><i class="fa fa-check"></i><b>7.7.3</b> sapply: a better way to do for loops</a></li>
<li class="chapter" data-level="7.7.4" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#how-many-monte-carlo-experiments-are-enough"><i class="fa fa-check"></i><b>7.7.4</b> How many Monte Carlo experiments are enough</a></li>
<li class="chapter" data-level="7.7.5" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#addition-rule"><i class="fa fa-check"></i><b>7.7.5</b> Addition Rule</a></li>
<li class="chapter" data-level="7.7.6" data-path="on-probability-and-statistics.html"><a href="on-probability-and-statistics.html#monty-hall-problem"><i class="fa fa-check"></i><b>7.7.6</b> Monty Hall Problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="reproducibility-and-the-replication-crisis.html"><a href="reproducibility-and-the-replication-crisis.html"><i class="fa fa-check"></i><b>8</b> Reproducibility and the replication crisis</a><ul>
<li class="chapter" data-level="8.1" data-path="reproducibility-and-the-replication-crisis.html"><a href="reproducibility-and-the-replication-crisis.html#answers-to-the-reproducibility-crisis-i-tweak-or-abandon-nhst"><i class="fa fa-check"></i><b>8.1</b> Answers to the reproducibility crisis I: Tweak or abandon NHST</a></li>
<li class="chapter" data-level="8.2" data-path="reproducibility-and-the-replication-crisis.html"><a href="reproducibility-and-the-replication-crisis.html#answers-to-the-reproducibility-crisis-ii-keep-a-log-of-every-step-of-every-analysis-in-r-markdown-or-jupyter-notebooks"><i class="fa fa-check"></i><b>8.2</b> Answers to the reproducibility crisis II: Keep a log of every step of every analysis in R markdown or Jupyter notebooks</a></li>
<li class="chapter" data-level="8.3" data-path="reproducibility-and-the-replication-crisis.html"><a href="reproducibility-and-the-replication-crisis.html#answers-to-the-reproducibility-crisis-iii-pre-registration"><i class="fa fa-check"></i><b>8.3</b> Answers to the reproducibility crisis III: Pre-registration</a></li>
<li class="chapter" data-level="8.4" data-path="reproducibility-and-the-replication-crisis.html"><a href="reproducibility-and-the-replication-crisis.html#further-readings"><i class="fa fa-check"></i><b>8.4</b> Further readings</a></li>
</ul></li>
<li class="part"><span><b>III Part III Towards data proficiency</b></span></li>
<li class="chapter" data-level="9" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html"><i class="fa fa-check"></i><b>9</b> literate programming with R markdown</a><ul>
<li class="chapter" data-level="9.1" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html#scripts-are-files-of-code"><i class="fa fa-check"></i><b>9.1</b> scripts are files of code</a></li>
<li class="chapter" data-level="9.2" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html#projects-are-directories-containing-related-scripts"><i class="fa fa-check"></i><b>9.2</b> projects are directories containing related scripts</a></li>
<li class="chapter" data-level="9.3" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html#r-markdown-documents-integrate-rationale-script-and-results"><i class="fa fa-check"></i><b>9.3</b> R markdown documents integrate rationale, script, and results</a></li>
<li class="chapter" data-level="9.4" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html#what-to-do-when-you-are-stuck"><i class="fa fa-check"></i><b>9.4</b> What to do when you are stuck</a></li>
<li class="chapter" data-level="9.5" data-path="literate-programming-with-r-markdown.html"><a href="literate-programming-with-r-markdown.html#appendix-a-few-possible-data-challenges"><i class="fa fa-check"></i><b>9.5</b> appendix: a few possible data challenges</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="the-tidyverse.html"><a href="the-tidyverse.html"><i class="fa fa-check"></i><b>10</b> the tidyverse</a><ul>
<li class="chapter" data-level="10.1" data-path="the-tidyverse.html"><a href="the-tidyverse.html#some-simple-principles"><i class="fa fa-check"></i><b>10.1</b> some simple principles</a></li>
<li class="chapter" data-level="10.2" data-path="the-tidyverse.html"><a href="the-tidyverse.html#homework"><i class="fa fa-check"></i><b>10.2</b> homework</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="messy-data-cleaning-and-curation.html"><a href="messy-data-cleaning-and-curation.html"><i class="fa fa-check"></i><b>11</b> Messy data: Cleaning and curation</a><ul>
<li class="chapter" data-level="11.1" data-path="messy-data-cleaning-and-curation.html"><a href="messy-data-cleaning-and-curation.html#finding-data"><i class="fa fa-check"></i><b>11.1</b> finding data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="transforming-data.html"><a href="transforming-data.html"><i class="fa fa-check"></i><b>12</b> transforming data</a><ul>
<li class="chapter" data-level="12.1" data-path="transforming-data.html"><a href="transforming-data.html#from-data-on-the-web-to-data-in-r"><i class="fa fa-check"></i><b>12.1</b> from data on the web to data in R</a></li>
<li class="chapter" data-level="12.2" data-path="transforming-data.html"><a href="transforming-data.html#babynames"><i class="fa fa-check"></i><b>12.2</b> babynames</a></li>
<li class="chapter" data-level="12.3" data-path="transforming-data.html"><a href="transforming-data.html#exercises"><i class="fa fa-check"></i><b>12.3</b> exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="relational-data.html"><a href="relational-data.html"><i class="fa fa-check"></i><b>13</b> relational data</a></li>
<li class="chapter" data-level="14" data-path="strings-factors-dates-and-times.html"><a href="strings-factors-dates-and-times.html"><i class="fa fa-check"></i><b>14</b> strings, factors, dates, and times</a><ul>
<li class="chapter" data-level="14.1" data-path="strings-factors-dates-and-times.html"><a href="strings-factors-dates-and-times.html#strings"><i class="fa fa-check"></i><b>14.1</b> strings</a></li>
<li class="chapter" data-level="14.2" data-path="strings-factors-dates-and-times.html"><a href="strings-factors-dates-and-times.html#factors"><i class="fa fa-check"></i><b>14.2</b> factors</a></li>
<li class="chapter" data-level="14.3" data-path="strings-factors-dates-and-times.html"><a href="strings-factors-dates-and-times.html#dates"><i class="fa fa-check"></i><b>14.3</b> dates</a></li>
<li class="chapter" data-level="14.4" data-path="strings-factors-dates-and-times.html"><a href="strings-factors-dates-and-times.html#times"><i class="fa fa-check"></i><b>14.4</b> times</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="lists.html"><a href="lists.html"><i class="fa fa-check"></i><b>15</b> lists</a></li>
<li class="chapter" data-level="16" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html"><i class="fa fa-check"></i><b>16</b> loops, functions, and beyond</a><ul>
<li class="chapter" data-level="16.1" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#loops"><i class="fa fa-check"></i><b>16.1</b> loops</a></li>
<li class="chapter" data-level="16.2" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#from-loop-to-apply-to-purrrmap"><i class="fa fa-check"></i><b>16.2</b> from loop to apply to purrr::map</a></li>
<li class="chapter" data-level="16.3" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#some-examples-of-functions"><i class="fa fa-check"></i><b>16.3</b> some examples of functions</a><ul>
<li class="chapter" data-level="16.3.1" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#preliminaries"><i class="fa fa-check"></i><b>16.3.1</b> preliminaries</a></li>
<li class="chapter" data-level="16.3.2" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#the-function"><i class="fa fa-check"></i><b>16.3.2</b> the function</a></li>
<li class="chapter" data-level="16.3.3" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#applying-the-function"><i class="fa fa-check"></i><b>16.3.3</b> applying the function</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="loops-functions-and-beyond.html"><a href="loops-functions-and-beyond.html#how-many-bottles-of-what"><i class="fa fa-check"></i><b>16.4</b> how many bottles of what?</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html"><i class="fa fa-check"></i><b>17</b> Regression and Modeling</a><ul>
<li class="chapter" data-level="17.1" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#correlation"><i class="fa fa-check"></i><b>17.1</b> Correlation</a><ul>
<li class="chapter" data-level="17.1.1" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#the-regression-line"><i class="fa fa-check"></i><b>17.1.1</b> The regression line</a></li>
<li class="chapter" data-level="17.1.2" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#warning-there-are-two-regression-lines"><i class="fa fa-check"></i><b>17.1.2</b> Warning: there are two regression lines</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#multiple-regression"><i class="fa fa-check"></i><b>17.2</b> Multiple regression</a></li>
<li class="chapter" data-level="17.3" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#swiss-fertility"><i class="fa fa-check"></i><b>17.3</b> Swiss fertility</a></li>
<li class="chapter" data-level="17.4" data-path="regression-and-modeling.html"><a href="regression-and-modeling.html#what-predicts-marital-affairs"><i class="fa fa-check"></i><b>17.4</b> What predicts marital affairs?</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html"><i class="fa fa-check"></i><b>18</b> From regression to prediction and classification</a><ul>
<li class="chapter" data-level="18.1" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#revisiting-the-affairs-data"><i class="fa fa-check"></i><b>18.1</b> Revisiting the affairs data</a></li>
<li class="chapter" data-level="18.2" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#avoiding-capitalizing-on-chance"><i class="fa fa-check"></i><b>18.2</b> Avoiding capitalizing on chance</a><ul>
<li class="chapter" data-level="18.2.1" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#splitting-the-data-into-training-and-test-subsamples"><i class="fa fa-check"></i><b>18.2.1</b> Splitting the data into training and test subsamples</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#applying-logistic-regression-analysis-to-the-training-data"><i class="fa fa-check"></i><b>18.3</b> applying logistic regression analysis to the training data</a></li>
<li class="chapter" data-level="18.4" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#from-regression-to-classification"><i class="fa fa-check"></i><b>18.4</b> From regression to classification</a></li>
<li class="chapter" data-level="18.5" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#applying-the-model-to-new-data-assessing-out-of-sample-risk"><i class="fa fa-check"></i><b>18.5</b> Applying the model to new data: Assessing out-of-sample risk</a></li>
<li class="chapter" data-level="18.6" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#changing-our-decision-threshold"><i class="fa fa-check"></i><b>18.6</b> Changing our decision threshold</a></li>
<li class="chapter" data-level="18.7" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#more-confusion"><i class="fa fa-check"></i><b>18.7</b> More confusion</a></li>
<li class="chapter" data-level="18.8" data-path="from-regression-to-prediction-and-classification.html"><a href="from-regression-to-prediction-and-classification.html#rocs-and-auc"><i class="fa fa-check"></i><b>18.8</b> ROCs and AUC</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="another-approach-to-prediction-k-nearest-neighbor.html"><a href="another-approach-to-prediction-k-nearest-neighbor.html"><i class="fa fa-check"></i><b>19</b> Another approach to prediction: k-nearest neighbor</a><ul>
<li class="chapter" data-level="19.1" data-path="another-approach-to-prediction-k-nearest-neighbor.html"><a href="another-approach-to-prediction-k-nearest-neighbor.html#from-1-doppelganger-to-many"><i class="fa fa-check"></i><b>19.1</b> From 1 doppelganger to many</a></li>
<li class="chapter" data-level="19.2" data-path="another-approach-to-prediction-k-nearest-neighbor.html"><a href="another-approach-to-prediction-k-nearest-neighbor.html#avoiding-capitalization-on-chance-again"><i class="fa fa-check"></i><b>19.2</b> Avoiding capitalization on chance (again)</a></li>
<li class="chapter" data-level="19.3" data-path="another-approach-to-prediction-k-nearest-neighbor.html"><a href="another-approach-to-prediction-k-nearest-neighbor.html#the-multinomial-case"><i class="fa fa-check"></i><b>19.3</b> The multinomial case</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>20</b> references</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data science for the liberal arts</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="from-regression-to-prediction-and-classification" class="section level1">
<h1><span class="header-section-number">18</span> From regression to prediction and classification</h1>
<div id="revisiting-the-affairs-data" class="section level2">
<h2><span class="header-section-number">18.1</span> Revisiting the affairs data</h2>
<p>Let’s go back and do what we should have done earlier: Examine and think about “number of affairs”. What does the distribution look like?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Fair)
Fair <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(nbaffairs)</code></pre>
<pre><code>## # A tibble: 6 x 2
##   nbaffairs     n
##       &lt;dbl&gt; &lt;int&gt;
## 1         0   451
## 2         1    34
## 3         2    17
## 4         3    19
## 5         7    42
## 6        12    38</code></pre>
<p>We note that the distibution is skewed - and we realize that perhaps we should think about it differently: The <em>meaning</em> of the difference between 0 and 1 is not the same as that between 1 and 2, or perhaps even 1 and 12.</p>
<p>We can transform the data in several ways. We might begin with a root transform, rounded as integer:</p>
<pre class="sourceCode r"><code class="sourceCode r">Fair2 &lt;-<span class="st"> </span>Fair <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">rootAffair =</span> 
              <span class="kw">as.integer</span>(<span class="kw">sqrt</span>(nbaffairs)))
Fair2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(rootAffair)</code></pre>
<pre><code>## # A tibble: 4 x 2
##   rootAffair     n
##        &lt;int&gt; &lt;int&gt;
## 1          0   451
## 2          1    70
## 3          2    42
## 4          3    38</code></pre>
<p>Or we could simply distinguish between those that do and don’t have affairs. We are going to do this on our initial (Fair) data here as we will be examining this further:</p>
<pre class="sourceCode r"><code class="sourceCode r">Fair &lt;-<span class="st"> </span>Fair <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">affairYN =</span>
               <span class="kw">ifelse</span> (nbaffairs <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))
Fair <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(affairYN)</code></pre>
<pre><code>## # A tibble: 2 x 2
##   affairYN     n
##      &lt;dbl&gt; &lt;int&gt;
## 1        0   451
## 2        1   150</code></pre>
<p>With this change, the regression problem becomes more clearly a classification problem. How can we best predict which ‘type’ (affair-ers vs. not) a given person falls in to?</p>
</div>
<div id="avoiding-capitalizing-on-chance" class="section level2">
<h2><span class="header-section-number">18.2</span> Avoiding capitalizing on chance</h2>
<p>One lesson from the last class was that correlations (and regression coefficients) drawn from small samples were not stable. In regression analysis, as progressively smaller samples were drawn from the Fair data, the ability to predict the outcome increased. In the limiting case, when the number of predictors (variables) was equal to the number of cases in the sample (rows), prediction becomes perfect.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># insert code here to show this</span></code></pre>
<p>The problem of capitalizing on chance is a significant one in prediction, and one should always be skeptical of models which are untested beyond the sample from which they were derived.</p>
<div id="splitting-the-data-into-training-and-test-subsamples" class="section level3">
<h3><span class="header-section-number">18.2.1</span> Splitting the data into training and test subsamples</h3>
<p>The most basic solution to this problem is to split the data into two groups, a <em>training</em> sample from which we extract our model, and a <em>test</em> sample on which you will assess it. (Often, the logic of this will be extended to include a third group, a <em>validation</em> sample which would be used to tune or select the results of the training run before the test data are examined). Here, we will consider the simpler approach, splitting the Fair data into training and test samples. The critical feature of this analysis is that we will hold out the test data, and not even look at it until after our model building is complete.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># establish a seed for your data-split</span>
<span class="co"># so that your results will be reproducible</span>
<span class="kw">set.seed</span>(<span class="dv">33458</span>)
<span class="co"># drop the nbaffairs variable as we</span>
<span class="co"># are no longer using this</span>
Fair &lt;-<span class="st"> </span>Fair <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span> (<span class="op">-</span>nbaffairs)
<span class="co"># create a set of line numbers </span>
<span class="co"># of size corresponding to the </span>
<span class="co"># desired training sample </span>
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(Fair)
trainIndex &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>n, 
<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.6</span><span class="op">*</span>n), <span class="dt">replace=</span><span class="ot">FALSE</span>)
<span class="co"># create training and test samples</span>
trainFair &lt;-<span class="st"> </span>Fair[trainIndex ,]
testFair &lt;-<span class="st"> </span>Fair[<span class="op">-</span>trainIndex ,]</code></pre>
</div>
</div>
<div id="applying-logistic-regression-analysis-to-the-training-data" class="section level2">
<h2><span class="header-section-number">18.3</span> applying logistic regression analysis to the training data</h2>
<p>Last class, we used the lm command in our regression analysis which predicted the (continuous) outcome nbaffairs. Here, the outcome is now dichotomous and therefore binomially distributed variable, and so the desired regression is a logistic one. We run this analysis using only the training data.</p>
<pre class="sourceCode r"><code class="sourceCode r">model2 &lt;-<span class="st"> </span><span class="kw">glm</span>(affairYN <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> trainFair,
              <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span> (model2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = affairYN ~ ., family = &quot;binomial&quot;, data = trainFair)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5415  -0.7703  -0.5984   0.9298   2.2685  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  1.71899    1.16225   1.479  0.13914    
## sexmale      0.27875    0.31051   0.898  0.36934    
## age         -0.06421    0.02418  -2.655  0.00792 ** 
## ym           0.10580    0.04176   2.534  0.01128 *  
## childyes     0.38298    0.37743   1.015  0.31025    
## religious   -0.29793    0.11492  -2.592  0.00953 ** 
## education    0.01071    0.06673   0.160  0.87254    
## occupation   0.07694    0.09288   0.828  0.40749    
## rate        -0.42725    0.11950  -3.575  0.00035 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 411.94  on 360  degrees of freedom
## Residual deviance: 375.13  on 352  degrees of freedom
## AIC: 393.13
## 
## Number of Fisher Scoring iterations: 4</code></pre>
</div>
<div id="from-regression-to-classification" class="section level2">
<h2><span class="header-section-number">18.4</span> From regression to classification</h2>
<p>Our “predicted scores” are continuous, corresponding to the probability that a given person will have an affair. Here’s how they are distributed (still on the training data here):</p>
<pre class="sourceCode r"><code class="sourceCode r">predictTrain &lt;-<span class="st"> </span><span class="kw">predict</span>(model2, trainFair, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">summary</span> (predictTrain)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 0.03821 0.15515 0.21647 0.25762 0.34893 0.73426</code></pre>
<p>If we want to classify people, we will need to create a decision threshold at which we will change our prediction from no to yes.</p>
<p>One approach is to create a threshold equal to the actual proportion of people who don’t have affairs in our sample.</p>
<pre class="sourceCode r"><code class="sourceCode r">(threshold &lt;-<span class="st"> </span><span class="kw">mean</span>(trainFair<span class="op">$</span>affairYN))</code></pre>
<pre><code>## [1] 0.2576177</code></pre>
<p>This is equal to both the mean of our predicted scores (above) and the mean of our actual scores, and, because this is a dichotomous variable, the proportion of people in the sample who have affairs. We’ll predict that if a person has a predicted score more than this we’ll predict that s/he will be unfaithful, else we will “PredictOK.” Then we will create a <em>confusion matrix,</em> to compare our correct predictions (PredictOK and affairYN = 1, Predictunfaithful and affairYN = 0) with the remainder.</p>
<pre class="sourceCode r"><code class="sourceCode r">classification &lt;-<span class="st"> </span><span class="kw">ifelse</span>(predictTrain <span class="op">&gt;</span><span class="st"> </span>threshold,
                         <span class="st">&quot;Predictunfaithful&quot;</span>, <span class="st">&quot;PredictOK&quot;</span>)
(b &lt;-<span class="st"> </span><span class="kw">table</span>(classification, trainFair<span class="op">$</span>affairYN))</code></pre>
<pre><code>##                    
## classification        0   1
##   PredictOK         179  36
##   Predictunfaithful  89  57</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(correct &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">2</span>])</code></pre>
<pre><code>## [1] 236</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(errors &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">1</span>])</code></pre>
<pre><code>## [1] 125</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(accuracy &lt;-<span class="st"> </span>correct<span class="op">/</span>(correct <span class="op">+</span><span class="st"> </span>errors))</code></pre>
<pre><code>## [1] 0.6537396</code></pre>
</div>
<div id="applying-the-model-to-new-data-assessing-out-of-sample-risk" class="section level2">
<h2><span class="header-section-number">18.5</span> Applying the model to new data: Assessing out-of-sample risk</h2>
<p>We shouldn’t trust these results, though, because the model is based on the same data that it is tested upon. Now we will apply the model to the new, independent test data.</p>
<p>Typically (but not invariably), the percent of accurate classifications will decline, especially if the model is a complex one with many variables or if the number of observations is low.</p>
<pre class="sourceCode r"><code class="sourceCode r">predictTest &lt;-<span class="st"> </span><span class="kw">predict</span>(model2, testFair, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
classification &lt;-<span class="st"> </span><span class="kw">ifelse</span>(predictTest <span class="op">&gt;</span><span class="st"> </span>threshold,
                         <span class="st">&quot;Predictunfaithful&quot;</span>, <span class="st">&quot;PredictOK&quot;</span>)
(b &lt;-<span class="st"> </span><span class="kw">table</span>(classification, testFair<span class="op">$</span>affairYN))</code></pre>
<pre><code>##                    
## classification        0   1
##   PredictOK         126  18
##   Predictunfaithful  57  39</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(correct &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">2</span>])</code></pre>
<pre><code>## [1] 165</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(errors &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">1</span>])</code></pre>
<pre><code>## [1] 75</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(accuracy &lt;-<span class="st"> </span>correct<span class="op">/</span>(correct <span class="op">+</span><span class="st"> </span>errors))</code></pre>
<pre><code>## [1] 0.6875</code></pre>
<p>We are correct 69 percent of the time.</p>
</div>
<div id="changing-our-decision-threshold" class="section level2">
<h2><span class="header-section-number">18.6</span> Changing our decision threshold</h2>
<p>In many decision problems, there is an asymmetry in the cost of different types of errors: if you are foraging for mushrooms, for example, an error of the form (you decide its safe and it is poisonous) is more costly than the converse (you decide its poisonous and it is safe).</p>
<p>This may be true in the present example as well. Consider someone who is looking for a spouse, but is really averse to the idea of getting hurt by an affair. That person might feel like the cost of marrying an unfaithful person is much greater than the cost of not marrying a faithful one. So we adjust the threshold downwards:</p>
<pre class="sourceCode r"><code class="sourceCode r">threshold &lt;-<span class="st"> </span><span class="fl">.05</span>
classification &lt;-<span class="st"> </span><span class="kw">ifelse</span>(predictTest <span class="op">&gt;</span><span class="st"> </span>threshold,
                         <span class="st">&quot;Predictunfaithful&quot;</span>, <span class="st">&quot;PredictOK&quot;</span>)
(b &lt;-<span class="st"> </span><span class="kw">table</span>(classification, testFair<span class="op">$</span>affairYN))</code></pre>
<pre><code>##                    
## classification        0   1
##   PredictOK           3   1
##   Predictunfaithful 180  56</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(correct &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">2</span>])</code></pre>
<pre><code>## [1] 59</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(errors &lt;-<span class="st">  </span>b[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">1</span>])</code></pre>
<pre><code>## [1] 181</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(accuracy &lt;-<span class="st"> </span>correct<span class="op">/</span>(correct <span class="op">+</span><span class="st"> </span>errors))</code></pre>
<pre><code>## [1] 0.2458333</code></pre>
<p>The “overall accuracy” - that is, number of correct classifications - drops. But that’s not what we are really interested in, rather, we are interested in minimizing hurt.</p>
<p>Here’s another example: Someone who is very lonely might feel the opposite, and be willing to accept greater substantially greater risk.</p>
<pre class="sourceCode r"><code class="sourceCode r">threshold &lt;-<span class="st"> </span><span class="fl">.5</span>
classification &lt;-<span class="st"> </span><span class="kw">ifelse</span>(predictTest <span class="op">&gt;</span><span class="st"> </span>threshold,
                         <span class="st">&quot;Predictunfaithful&quot;</span>, <span class="st">&quot;PredictOK&quot;</span>)
(b &lt;-<span class="st"> </span><span class="kw">table</span>(classification, testFair<span class="op">$</span>affairYN))</code></pre>
<pre><code>##                    
## classification        0   1
##   PredictOK         174  49
##   Predictunfaithful   9   8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(correct &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">2</span>])</code></pre>
<pre><code>## [1] 182</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(errors &lt;-<span class="st"> </span>b[<span class="dv">1</span>,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>b[<span class="dv">2</span>,<span class="dv">1</span>])</code></pre>
<pre><code>## [1] 58</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">(accuracy &lt;-<span class="st"> </span>correct<span class="op">/</span>(correct <span class="op">+</span><span class="st"> </span>errors))</code></pre>
<pre><code>## [1] 0.7583333</code></pre>
<p>Prediction is higher here - but not much higher than it would be if we raised the threshold even further, and just assumed that everyone can be trusted. Then, our error rate would be 26 percent. When overall predictability is low, it’s often the case that you can maximize correct predictions by simply predicting that everyone will be in the most popular category. Predicting rare events, such as suicides, is particularly difficult.</p>
</div>
<div id="more-confusion" class="section level2">
<h2><span class="header-section-number">18.7</span> More confusion</h2>
<p>There is a nice shortcut to generating confusion matrices such as those above using the caret package.</p>
<p>This function describes outcomes in several ways, as there are many languages for describing outcomes in 2 x 2 tables, including Type I vs. Type II errors, Hits vs. False Alarms/False Positives, and Sensitivity vs. Specificity.</p>
<p>In these data, it’s been set up so that
- hit rate ~ sensitivity ~ (“no affair” | no affair)
- correct rejection ~ specificity ~ (“affair” | affair)</p>
<pre class="sourceCode r"><code class="sourceCode r">threshold &lt;-<span class="st"> </span><span class="fl">.5</span>
<span class="co"># syntax for classification in caret is a little different</span>
<span class="co"># (the labels for the actual and predicted scores have to be the same)</span>
<span class="co">#classification &lt;- ifelse(predictTest &gt; threshold,</span>
<span class="co">#                         &quot;Predictunfaithful&quot;, &quot;PredictOK&quot;)</span>
classification &lt;-<span class="st"> </span><span class="kw">ifelse</span>(predictTest <span class="op">&gt;</span><span class="st"> </span>threshold, <span class="dv">1</span>,<span class="dv">0</span>)
<span class="co"># caret package (newest) requires explicit matching of factors</span>
classification &lt;-<span class="st"> </span><span class="kw">as.factor</span>(classification)
testFair<span class="op">$</span>affairYN &lt;-<span class="st"> </span><span class="kw">as.factor</span>(testFair<span class="op">$</span>affairYN)
<span class="kw">confusionMatrix</span>(classification, testFair<span class="op">$</span>affairYN)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 174  49
##          1   9   8
##                                           
##                Accuracy : 0.7583          
##                  95% CI : (0.6991, 0.8111)
##     No Information Rate : 0.7625          
##     P-Value [Acc &gt; NIR] : 0.5948          
##                                           
##                   Kappa : 0.1202          
##  Mcnemar&#39;s Test P-Value : 3.04e-07        
##                                           
##             Sensitivity : 0.9508          
##             Specificity : 0.1404          
##          Pos Pred Value : 0.7803          
##          Neg Pred Value : 0.4706          
##              Prevalence : 0.7625          
##          Detection Rate : 0.7250          
##    Detection Prevalence : 0.9292          
##       Balanced Accuracy : 0.5456          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
</div>
<div id="rocs-and-auc" class="section level2">
<h2><span class="header-section-number">18.8</span> ROCs and AUC</h2>
<p>Each of these decision thresholds describes the performance of a model at a particular point. We can combine the thresholds and plot them in Receiver Operating Characteristic (ROC) curves. The area under the curve (AUC) is a great measure of model accuracy, in that it summarizes how effective a classifier is across all possible thresholds.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fig.width and fig.height specified to get square plots</span>
<span class="co"># colAUC function gets stats etc</span>
AUCModel2&lt;-<span class="kw">colAUC</span>(predictTest, testFair[[<span class="st">&quot;affairYN&quot;</span>]], <span class="dt">plotROC =</span> <span class="ot">TRUE</span>)</code></pre>
<p><img src="DataSciLibArts_files/figure-html/0414model1ROC-1.png" width="480" /></p>
<pre class="sourceCode r"><code class="sourceCode r">AUCModel2</code></pre>
<pre><code>##              [,1]
## 0 vs. 1 0.7349727</code></pre>

<pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span>opts_chunk<span class="op">$</span><span class="kw">set</span>(<span class="dt">echo =</span> <span class="ot">TRUE</span>, <span class="dt">warn =</span> <span class="ot">FALSE</span>, <span class="dt">message =</span> <span class="ot">FALSE</span>) <span class="co"># defaults for all chunks after this one</span>
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(Ecdat) 
<span class="kw">library</span> (class) <span class="co"># for knn</span>
<span class="kw">library</span>(caret) <span class="co"># confusion matrix</span>
<span class="kw">library</span>(magrittr) <span class="co"># allows bidirectional pipe for updating file easily %&lt;&gt;% </span></code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-and-modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="another-approach-to-prediction-k-nearest-neighbor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sepia",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
