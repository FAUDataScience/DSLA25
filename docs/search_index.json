[
["transforming-data.html", "12 transforming data 12.1 from data on the web to data in R 12.2 working with geodata: a function to get US states from latitude/longitude 12.3 drowning in the sea of songs (with apologies to ARIVOIM1187B990643) 12.4 review of munging tools", " 12 transforming data Once you have your data, you will almost invariably need to transform it - to sort it, to select observations or variables from it, to create new variables, to partition it into groups, or to summarize it. In R, there is a general purpose tool (ok, package) that exists for this called dplyr (“d-plier”). Play with the various dplyr functions. Experiment. You will not break the internet Fig 12.1 - pliers to play with Dplyr is a core part of the tidyverse and hence is loaded automatically when you load the tidyverse ensemble of libraries: library(tidyverse) ## Warning: package &#39;tidyr&#39; was built under R version 3.6.3 ## Warning: package &#39;dplyr&#39; was built under R version 3.6.3 ## Warning: package &#39;forcats&#39; was built under R version 3.6.3 library(maps) library(maptools) ## Warning: package &#39;sp&#39; was built under R version 3.6.3 The versatility of dplyr is demonstrated in Chapter 5 of R4DS, which shows how to do many basic, and some not so basic, operations on your data. Read it closely if you haven’t already done so. 12.1 from data on the web to data in R Let’s consider a dataset consisting of 10,000 songs (observations) and 35 measures (variables including artist). The first step here (and for your class project and the data science challenge) will be to get the data into R. How do you this? Method 1: Download the file to your computer as a csv file. Some advantages of this include (a) it will allow the code to run even if the website changes or disappears, (b) in the likely event that I will run the code several times, it is faster to get data from my own machine than from the cloud, and (c) if there are any anomalies in the data I can look at them locally (e.g., in Notepad++). If you use this approach, make sure that you know where your data is on your computer. The easiest way to do this is to work with an R project. Within R studio, create a new R project (or use an existing one). Move the csv file into this directory, so that data, code, and results will all be in the same place. Method 2: Import the data from the cloud directly into R. You can do this either by specifying the musicURL separately (Method 2a) or call it directly within the read_csv statement (2b). Here, too, I would encourage you to set up and work within a project. ### Method 1 # music1 &lt;- read_csv(&quot;music.csv&quot;) ### Method 2a musicURL &lt;- &quot;https://think.cs.vt.edu/corgis/datasets/csv/music/music.csv?forcedownload=1&quot; music1 &lt;- read_csv(musicURL) ### Method 2b # music1 &lt;- read_csv( # &quot;https://think.cs.vt.edu/corgis/csv/music/music.csv?forcedownload=1&quot; # ) What can you do with the data in its existing form? What questions do you wish you could ask about these songs, artists, and the places they come from? 12.2 working with geodata: a function to get US states from latitude/longitude When I first ran this code in 2018, the variables included states and countries. The current dataset doesn’t have these, but it does have longitude and latitude. To get state data from this, reverse geocoding is needed. A Google search turned up the following function. Note that it requires two additional libraries, ‘maps’ and ‘maptools.’ # source is https://github.com/abresler # The single argument to this function, pointsDF, is a data.frame in which: # - column 1 contains the longitude in degrees (negative in the US) # - column 2 contains the latitude in degrees latlong2state &lt;- function(pointsDF) { # Prepare SpatialPolygons object with one SpatialPolygon # per state (plus DC, minus HI &amp; AK) states &lt;- map(&#39;state&#39;, fill=TRUE, col=&quot;transparent&quot;, plot=FALSE) IDs &lt;- sapply(strsplit(states$names, &quot;:&quot;), function(x) x[1]) states_sp &lt;- map2SpatialPolygons(states, IDs=IDs, proj4string=CRS(&quot;+proj=longlat +datum=WGS84&quot;)) # Convert pointsDF to a SpatialPoints object pointsSP &lt;- SpatialPoints(pointsDF, proj4string=CRS(&quot;+proj=longlat +datum=WGS84&quot;)) # Use &#39;over&#39; to get _indices_ of the Polygons object containing each point indices &lt;- over(pointsSP, states_sp) # Return the state names of the Polygons object containing each point stateNames &lt;- sapply(states_sp@polygons, function(x) x@ID) stateNames[indices] } 12.2.1 applying the function to the music data If you have run the chunk above, the latlong2state function will now exists in your environment. You still need to apply the function to your data. We do this using three of the essential tools in the munger’s toolbox: select (to choose several columns from the data), mutate (to create a new variable), and finally drop_na (to drop cases with missing data - here, artists from outside of the US). # create a new dataset with just latitude and longitude tempLatLong &lt;- music1 %&gt;% select (artist.longitude, artist.latitude) USartists &lt;- music1 %&gt;% mutate(state = latlong2state(tempLatLong)) %&gt;% drop_na(state) rm(tempLatLong) 12.3 drowning in the sea of songs (with apologies to ARIVOIM1187B990643) At this point, we have a list of songs and artists and some measures of “hotttness,” restricted to US artists and now including states as well as latitude and longitude. There is a field called song-id, but it doesn’t have song titles. (several hours later) I found the titles on the ’net. They were part of a file “millionsongsubset,” which is an archive of many files, and which is altogether about 2 GB in size. Within this, there is a file that looks right - let’s try it. The file is delimited by the characters “&lt;SEP&gt;”, but read_delim requires that data fields be separated by a single character (like a comma or a tab). So the file is read as a single variable, which R assigns the default name “X1”. I use mutate to replace each \"&lt;SEP&gt;\" by a tab, then the separate command to split X1 up into its constituent variables - the first is a mysterious ID, the second looks like the song.id in the original file, the third is an artist name, and the fourth is a song title. 12.3.1 combining the song titles with our US artists Finally, we can join this to the USartist data, as each row of the two files have a common key (song.id). We use a right_join - implicitly, “maybeTitles”, which is at the head of the pipe, is on the left. The right_join will link the left (maybeTitles) file with the right (USartists), by what appears to be a common key: maybeTitles &lt;- read_delim(&quot;subset_unique_tracks.txt&quot;,&quot;~&quot;, col_names = FALSE) %&gt;% mutate(X1 = str_replace_all(X1, &quot;&lt;SEP&gt;&quot;, &quot;\\t&quot;)) %&gt;% separate(X1, sep = &quot;\\t&quot;, into = c(&quot;ID1&quot;, &quot;song.id&quot;, &quot;artistFromMaybeTitles&quot;, &quot;SongTitle&quot;)) %&gt;% right_join(USartists, key = &quot;song.id&quot;) ## Parsed with column specification: ## cols( ## X1 = col_character() ## ) ## Joining, by = &quot;song.id&quot; So far, so good. Do things line up correctly? If the match is perfect, the two artist fields should be identical. We can use the [not] oddly-titled logical function “identical” to check this: identical(maybeTitles$artistFromMaybeTitles, maybeTitles$artist.name) ## [1] FALSE Whoops. The two variables aren’t the same - or are they? Run the following commands, which includes two more of the essential munging tools - select and arrange. Here, note that the “filter” function is used to select cases where the two variables are different. maybeTitles %&gt;% filter (artistFromMaybeTitles != artist.name) %&gt;% select (artistFromMaybeTitles, artist.name) %&gt;% arrange(artistFromMaybeTitles) %&gt;% head() ## # A tibble: 6 x 2 ## artistFromMaybeTitles artist.name ## &lt;chr&gt; &lt;chr&gt; ## 1 Alvin Youngblood Hart Alvin YoungbloodA Hart ## 2 Andraé Crouch &amp; Solid Gospel AndraA(c) Crouch &amp; Solid Gospel ## 3 Angélica María AngA(c)lica MarAa ## 4 Fabián FabiA!n ## 5 Ill Niño Ill NiA+-o ## 6 Los Muñequitos De Matanzas Los MuA+-equitos De Matanzas 12.3.2 exercises What happened with the artist names? How would you move forward with these data? Do something interesting with the data - use filter, arrange, and select in your piped code. Work with the babynames data. Use mutate to create an interesting new variable. most importantly, make progress on your class project. You will be presenting this two weeks from today. 12.4 review of munging tools The primary tools, at least in my experience, are these: If you want to pull out only certain columns, use select. If you want to pull out only certain rows, use filter. If you want to sort, you arrange. If you want to create, you mutate. If you have two datasets with a common key (an identifier), you join. 12.4.1 and still more munging We’ve also used separate to split a column into several; the complement of this is unite. You may want to add new measures for all cases without a common key. Here, you can use the bind_cols function. If you instead want to add observations to an existing dataframe, you may bind_rows. We haven’t yet considered the tools used to reshape data frames from short-and-wide to long-and-narrow, and vice-versa. In our music data, we might, for example, want to think about the data by artist (with possibly multiple songs on each line), or song-titles (with possibly covers by different artists on each line). More typically, consider repeated-measures data in which each score reflects a measure taken on one of ten subjects and one of three occasions - for example, scores on the Beck Depression Inventory (BDI) before, during, and after treatment. Here, we may wish to structure the data in a “long” format with thirty rows (one for each subject X occasion) and three columns (person, occasion, and BDI), or in a “wide” format with just ten rows (one for each subject), and four columns (person, BDI-before, etc). To move from “long” to “wide,” use the spread command, and to move instead from “wide” to “long,” use gather. "]
]
