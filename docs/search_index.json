[
["visualization-in-r-with-ggplot.html", "6 visualization in R with ggplot 6.1 a picture &gt; (words, numbers)? 6.2 Read Hadley ggplots 6.3 exploring more data 6.4 Advanced: Tracking the Novel Coronavirus", " 6 visualization in R with ggplot In the last chapter, we introduced data visualization, citing “vision-aries” including Edward Tufte and Hans Rosling, inspired works such as Minard’s Carte Figurative and Periscopic’s stolen years, as well as a few cautionary tales of misleading and confusing graphs. Here, in playing with and learning the R package ggplot, we begin to move from consumers to creators of data visualizations. As the first visualization in Wickham and Grolemund (2016) reminds us, data visualization is at the core of exploratory data analysis: Fig 6.1: Data visualization is at the core of data analysis (Wickham and Grolemund (2016)) In the world of data science, statistical programming is about discovering and communicating truths within your data. This exploratory data analysis is the corner of science, particularly at a time in which confirmatory studies are increasingly found to be unreproducible. Most of your reading will be from Chapter 3 of Wickham and Grolemund (2016), this is intended only as a supplement. 6.1 a picture &gt; (words, numbers)? The chapter begins with a quote from John Tukey about the importance of graphs. Yet there is a tendency among some statisticians and scientists to discount graphs, to consider graphic representations of data as less valuable than statistical ones. It is true that, because there are many ways to graph data, and because scientists and data journalists are humans with pre-existing beliefs and values, a graphical displays should not be assumed to simply depict a singular reality. But the same can be said about statistical analyses (see Chapter 8). To consider the value of statistical versus graphical displays, consider ‘Anscombe’s quartet’ (screenshot below, live at http://bit.ly/anscombe2019): Table 6.1: An adaptation of Anscombe’s “quartet” (Anscombe 1973) Exercise 6_1 Consider the spreadsheet chunk presented above, which I am characterizing as data collected on a sample of ten primary school children at recess on four consecutive days. Working with your classmates, compute the mean, standard deviation, and correlation between the two measures for one day. Share your results with the class. The four pairs of variables in Anscombe (1973) appear statistically “the same,” yet the data suggest something else. Later, we’ll try to plot these. Perhaps graphs can reveal truths that statistics can hide. 6.2 Read Hadley ggplots In class, we will review and recreate the plots in section 3.2 of Wickham and Grolemund (2016) and exercises through 3.4. Savor this section, reading slowly, and playing around with the RStudio interface. For example, read about the mpg data in the ‘help’ panel, pull up the mpg data in a view window, and sort through it by clicking on various columns. Fig. 6.2: A screenshot from RStudio, showing the mpg dataset 6.3 exploring more data Explore the Gapminder data https://cran.r-project.org/web/packages/gapminder/README.html Choose one of the datasets in R, pull out a few variables, and explore these. Try to make a cool graph - one that informs the viewer, and, to paraphrase Tukey, helps us see what we don’t expect. Try several different displays. Which fail? Which succeed? Be prepared to share your efforts. Don’t be afraid to screw up. 6.4 Advanced: Tracking the Novel Coronavirus Here, I want to consider a timely (but challenging) dataset - a live list of cases and places where cases of the novel Coronavirus, which has (at this writing) just been declared a public health emergency by the World Health Organization. This first chunk loads libraries and gets access to the data: library(tidyverse) # libraries for reading google docs from Jenny Bryan library(googledrive) library(googlesheets4) # bidirectional pipe library(magrittr) # for working with dates library(lubridate) # and making graphs interactive library(plotly) library(htmlwidgets) drive_deauth() sheets_deauth() coronaURL &lt;- &quot;https://docs.google.com/spreadsheets/d/1wQVypefm946ch4XDp37uZ-wartW4V7ILdg-qYiDXUHM&quot; nsheets &lt;- sheets_get(as_id(coronaURL)) %&gt;% extract2(6) %&gt;% # gets the sixth element in a list nrow() # to look at one sheet, uncomment the following # i = 1 # j &lt;- sheets_read(as_id(coronaURL), sheet = i) 6.4.1 Reading the data The Novel Coronavirus data consists of a series of tabs in a Google Sheet. This finds them and combines them into a single sheet in R. # variables to retain or create numvars &lt;- c(&quot;Confirmed&quot;, &quot;Deaths&quot;, &quot;Recovered&quot;) varlist &lt;- c(&quot;Province/State&quot;, &quot;Country/Region&quot;, &quot;Last Update&quot;, numvars) # one cool trick to initialize a tibble coronaData &lt;- varlist %&gt;% map_dfr( ~tibble(!!.x := logical() ) ) # add data from Google sheet to tibble for (i in 1:(nsheets-1)) { j &lt;- sheets_read(as_id(coronaURL), sheet = i) # if a variable doesn&#39;t exist in sheet, add it j[setdiff(varlist,names(j))] &lt;- NA j %&lt;&gt;% select(varlist) coronaData &lt;- rbind(coronaData, j) } # the first (earliest) sheet had different var names for (i in (nsheets):(nsheets)) { j &lt;- sheets_read(as_id(coronaURL), sheet = i) %&gt;% mutate(`Last Update` = `Date last updated`) j[setdiff(varlist,names(j))] &lt;- NA j %&lt;&gt;% select(varlist) coronaData &lt;- rbind(coronaData, j) } 6.4.2 Cleaning (wrangling, munging) the data Cleaning the data includes not just finding “errors,” but adapting it for our own use. It’s generally time consuming (as was the case here). The following letters refer to sections of the code below. a - fix a few missing values outside of China for province and country b - the earliest cases, all in China, did not include country c - because province/state is included inconsistently, an unambiguous place variable is created d - reportdate is renamed (because) e - in some cases, multiple reports are issued for each day. only the last of these is used for each place. f - for dates where no data was supplied, the most recent (previous) data are used g - values of NA for Deaths, Confirmed, and Recovered cases are replaced by zero. h - Prior to Feb 1, reporting for US included only state, since then, city and state. This drops the (duplicated) province/state-only values beginning Feb 1. coronaData %&lt;&gt;% # a mutate (`Province/State` = case_when( (is.na(`Province/State`) &amp; (`Country/Region` == &quot;Australia&quot;)) ~ &quot;New South Wales&quot;, (is.na(`Province/State`) &amp; (`Country/Region` == &quot;Germany&quot;)) ~ &quot;Bavaria&quot;, TRUE ~ `Province/State`)) %&gt;% mutate (`Country/Region` = case_when( `Province/State` == &quot;Hong Kong&quot; ~ &quot;Hong Kong&quot;, `Province/State` == &quot;Taiwan&quot; ~ &quot;Taiwan&quot;, `Province/State` == &quot;Washington&quot; ~ &quot;US&quot;, # b is.na (`Country/Region`) ~ &quot;Mainland China&quot;, TRUE ~ `Country/Region`)) %&gt;% # c mutate(place = ifelse(is.na(`Province/State`), `Country/Region`, paste0(`Province/State`,&quot;, &quot;, `Country/Region`))) %&gt;% # d mutate(reportDate = date(`Last Update`)) %&gt;% group_by(place,reportDate) %&gt;% # e slice(which.max(`Last Update`)) %&gt;% select(-c(place,`Last Update`)) %&gt;% ungroup() %&gt;% # f group_by(place) %&gt;% complete(reportDate = seq.Date(min(reportDate), today(), by=&quot;day&quot;)) %&gt;% fill(c(Confirmed,Deaths,Recovered, `Country/Region`,`Province/State`)) %&gt;% # g mutate_if(is.numeric, ~replace_na(., 0)) %&gt;% ungroup() %&gt;% # h mutate(dropcase = ((!str_detect(`Province/State`,&quot;,&quot;)) &amp; (reportDate &gt; &quot;2020-01-31&quot;) &amp; (`Country/Region` == &quot;Canada&quot; | `Country/Region` == &quot;US&quot;))) %&gt;% # dplyr called explicitly here because plotly has taken over &#39;filter&#39; dplyr::filter (!dropcase) ## Adding missing grouping variables: `place``mutate_if()` ignored the following grouping variables: ## Column `place` 6.4.3 Simplifying the data: China and the rest of the world This separates data into three locations, breaking down China into Hubei (Wuhan) and other, then summarizes results: coronaDataSimple &lt;- coronaData %&gt;% mutate(country = case_when( str_detect(`Country/Region`,&quot;China&quot;) ~ &quot;China&quot;, TRUE ~ &quot;Other countries&quot;)) %&gt;% mutate(location = case_when( place == &quot;Hubei, Mainland China&quot; ~ &quot;Hubei (Wuhan)&quot;, country == &quot;China&quot; ~ &quot;Other China&quot;, TRUE ~ &quot;Outside of China&quot;)) %&gt;% group_by(location,reportDate) %&gt;% summarize(Confirmed = sum(Confirmed), Deaths = sum(Deaths), Recovered = sum(Recovered)) %&gt;% ungroup() 6.4.4 Plotting some initial results The first plot is simple, including data for only deaths. A caption is added to show the source of the data. myCaption &lt;- &quot; Data courtesy JHU/CSSE http://bit.ly/ncvdata&quot; coronaPlot0 &lt;- coronaDataSimple %&gt;% ggplot(aes(x=reportDate)) + geom_line(aes(y=Deaths, color = location)) + labs(caption = myCaption) coronaPlot0 6.4.5 Adding recovered cases to the plot Here, recovered cases and deaths are included (as these are roughly on the same scale). Additional changes to the plot are self-evident. mySubtitle &lt;- paste0( &quot;Recovered cases (solid line) and deaths (dotted) by region through &quot;, (month(today())), &quot;/&quot;, (day(today())),&quot;/&quot;, (year(today())),&quot;.&quot;) myCaption &lt;- &quot; Data courtesy JHU/CSSE http://bit.ly/ncvdata&quot; coronaPlot1 &lt;- coronaDataSimple %&gt;% ggplot(aes(x=reportDate)) + geom_line(aes(y=Recovered, color = location), linetype = &quot;solid&quot;) + geom_line(aes(y=Deaths, color = location), linetype = &quot;dotted&quot;) + theme(axis.title.y = element_text(angle = 90, vjust = 1,size = 14), legend.position = (c(.2,.8))) + labs(title = &quot;Novel coronavirus&quot;, subtitle = mySubtitle, y = &quot;Cases&quot;, caption = myCaption) coronaPlot1 6.4.6 Making the graph interactive Plotly is an open-source, javascript based library that produces interactive graphs. The syntax that Plotly requires is (a little) different from ggplot, so, for example, the subtitle and caption are folded in to the title here, and the legend is moved a little further over. p &lt;- ggplotly(coronaPlot1) %&gt;% # make interactive layout(legend = list(x=.1,y=.9), title = list(text = paste0(&#39;Novel coronavirus&#39;, &#39;&lt;br&gt;&#39;, &#39;&lt;sup&gt;&#39;, mySubtitle, myCaption, &#39;&lt;/sup&gt;&#39;))) saveWidget(p, file=&quot;coronaDeathsRecovered.html&quot;) p 6.4.7 Plotting confirmed cases In this last figure, data for confirmed cases are shown (only the interactive version is included here): mySubtitle &lt;- paste0( &quot;Confirmed cases by region through &quot;, (month(today())), &quot;/&quot;, (day(today())),&quot;/&quot;, (year(today())),&quot;.&quot;) coronaPlot2 &lt;- coronaDataSimple %&gt;% ggplot(aes(x=reportDate)) + geom_line(aes(y=Confirmed, color = location), linetype = &quot;solid&quot;) + theme(axis.title.y = element_text(angle = 90, vjust = 1,size = 14), legend.position = (c(.2,.8))) + labs(title = &quot;Novel coronavirus&quot;, subtitle = mySubtitle, y = &quot;Cases&quot;, caption = myCaption) p &lt;- ggplotly(coronaPlot2) %&gt;% # make interactive layout(legend = list(x=.1,y=.9), title = list(text = paste0(&#39;Novel coronavirus&#39;, &#39;&lt;br&gt;&#39;, &#39;&lt;sup&gt;&#39;, mySubtitle, myCaption, &#39;&lt;/sup&gt;&#39;))) saveWidget(p, file=&quot;coronaConfirmed.html&quot;) p 6.4.8 Some questions Consider the data and try to run the code yourself. What problems did you encounter? What parts need to be annotated more? What appears to be increasing more quickly - recovered cases or deaths? Paying particular attention to the section on cleaning, to what extent can you ‘reverse-engineer’ my code? Where is it confusing? (Remember the 15 minute rule). Can you improve on these plots? Some more challenging questions. What is (roughly) the shape of the function for each of the three variables, and for China/Other? What values would you expect for, say, ten days from now? 6.4.9 Additional notes If you are interested in looking at additional epidemiological datasets and how they might be looked at in R, consider this source by Tomás J. Aragón (https://bookdown.org/medepi/phds/). For Plotly in R, check out https://plotly-r.com/ References "]
]
