[
["index.html", "Data Science for the Liberal Arts 1 Data science for the liberal arts 1.1 Data science: statistics ~ Overstimulation: insufficient arousal 1.2 The Venn diagram model 1.3 Type C data science 1.4 Limits of the Venn model: Aspects or features of Data Science 1.5 The expertise dimension 1.6 Reviewing the syllabus", " Data Science for the Liberal Arts Kevin Lanning 2018-01-07 1 Data science for the liberal arts What is data science? 1.1 Data science: statistics ~ Overstimulation: insufficient arousal It has been said (by whom?) that the biggest difference between traditional stats and data science is that the former is typically concerned with making inferences from datasets that are too small, while the latter is concerned with extracting a signal from data that is or are too big. This is the question of the age. I’m not saying that statistics is boring On needles in haystacks, ADHD, and why data science is fundamental Primacy of editing, attention, especially today. How do you decide what matters? difference between statistics and data science and the challenge of editing, finding needles in the haystack of the world 1.2 The Venn diagram model Hochster (in Hicks &amp; Irizarry, 2017) describes two broad types of data scientists: Type A (Analysis) data scientists, whose skills are like those of an applied statistician, and Type B (Building) data scientists, whose skills lie in problem solving or coding, using the skills of the computer scientist. Hochster’s view of data science arguably omits a critical component of the field. Data science is driven not just by statistics and computer science, but also by “domain expertise:” 1.3 Type C data science The iconic Venn diagram model of data science suggests what we can call a “Type C data science.” It begins with “domain expertise” in your concentration in the arts, humanities, social and/or natural sciences, it both informs and can be informed by new methods and tools of data analysis, and it includes such things as communication (including writing and the design and display of quantitative data), collaboration (making use of the tools of team science), and citizenship (serving the public good, overcoming the digital divide, furthering social justice, increasing public health, diminishing human suffering, and making the world a more beautiful place). It’s shaped, too, by an awareness of the creepiness of living increasingly in a measured, observed world. 1.4 Limits of the Venn model: Aspects or features of Data Science 1.4.1 Statistics 1.4.2 Computing 1.4.3 Substantive knowledge - multifaceted 1.4.3.1 medicine, literature, etc This suggests a type c data science. but there is more. 1.4.4 Collaboration 1.4.4.1 includes team science, working groups 1.4.5 Communication 1.4.5.1 open science, reproducibility 1.4.5.2 writing 1.4.5.3 data viz 1.4.6 Pragmatism: Applications towards real-world goals 1.4.6.1 Ethical concerns and data for good 1.5 The expertise dimension literacy (can understand) to fluency (can practice) to leadership (can create new solutions or methods). Type C data science can also be characterized by a continuum of knowledge, skills, interests, and goals, ranging from that which characterizes the data consumer to the data citizen to the data science contributor Google and the liberal arts https://www.washingtonpost.com/news/answer-sheet/wp/2017/12/20/the-surprising-thing-google-learned-about-its-employees-and-what-it-means-for-todays-students/?sw_bypass=true&amp;utm_term=.23e48235d66e A challenge: Can you improve upon the venn diagram? 1.6 Reviewing the syllabus notion of progress rather than achievement what are your own goals for the class, in terms of the model described above? "],
["setting-up-your-computer.html", "2 Setting up your computer", " 2 Setting up your computer "],
["pretest.html", "3 Pretest", " 3 Pretest What do you know about data science, and what are your goals for the term? Express these in terms of the matrix described above. &quot; Your grade in the class will be based not just on what you know at the end of the term, but how much you have learned. Is it possible to incentivize students to do as well as they can on this first exam - to use our honor code to insure that they don’t ‘cheat down’ as they would not ‘cheat up’? Thinking that residualized final exam performance will be worth x % of grade (i.e., that students who have learned more than the typical student will receive a boost. Might fold this in to a participation/effort score). Better still is to use the pretest to identify students with expertise in particular areas - these students can earn points by helping others. So you can earn points by (a) learning more about particular topics than most of your classmates and/or by (b) helping your classmates with particular topics. Because the range of expertise required in the course is broad, every student will be identified as having one or more strengths, "],
["some-basic-tools-slack-markdown-and-google-docs.html", "4 Some basic tools: Slack, Markdown, and Google Docs", " 4 Some basic tools: Slack, Markdown, and Google Docs Markdown, Slack, and Google Docs/Sheets/Forms (Freeman and Ross (2017), Chapter 3) Gephi, Tableau, Github as optional. References "],
["an-introduction-to-r.html", "5 An introduction to R", " 5 An introduction to R R is a system for Reproducible science. Reproducibility is essential Baumer et al. (2014) R is a system for Representing data in cool, insight-facilitating ways. R is Really popular, and really gRowing. Historically, R grew out of S which could stand for Statistics. In the univeRse of data science classes, R is closeR to statistics than computer science. LeaRning R is woRthwhile and it will make you a more attractive candidate for many graduate programs as well as jobs in the private sector. But “learning R” is a misnomer, as it implies a discrete accomplishment that one can master, Rather, R is a system of applications and tools which is so vast that there is always more that one can achieve. There are many tools out there that can help you learn R, including SwirlR, DataCamp, the Data Science Certificate Program at Hopkins, your classmates, and the present text. R syntax is finicky. You will make errors constantly, but because so many other people are using R, you can generally find answers quickly with a Google search. (This achievement of scale is a characteristic feature of many aspects of our data-connected world, one in which popular restaraunts, hotels, … ) SwirlR lessons, Peng (2015), References "],
["finding-help.html", "6 Finding help", " 6 Finding help using google searches wisely generating reproducible errors "],
["empiricism-intuition.html", "7 Empiricism &gt; intuition", " 7 Empiricism &gt; intuition (which chapters and assignments from Bit by Bit?) A revolution in the social sciences. also Lazer et al. (2014) Introduction: Power of Google trends (which example is most compelling?). Chapters 1 and 2: Thinking like a data scientist. Empiricism &gt; intuition. Four powers of Big Data. P(player in NBA) doubles with each additional inch. References "],
["the-ubiquity-of-data.html", "8 The ubiquity of data", " 8 The ubiquity of data Chapter 3: reimagining data, Chapter 4 what google searches can tell us https://medium.com/@PaulStollery/all-of-the-fucks-given-online-in-2016-58c60edd6e44 Chapter 3-4: The internet as a network. Google searches and the Page Rank algorithm. Google flu. Google as a datasource (https://medium.com/@pewresearch/using-google-trends-data-for-research-here-are-6-questions-to-ask-a7097f5fb526) autocomplete (use an anonymous/incognito window?) Searches for is my son … vs is my daughter… trends correlate books: https://books.google.com/ngrams Google correlate (I tried this but it is finicky / weeks must begin on a sunday - enter a time series, see what correlates with it.) Data challenge: Find an interesting time series, use google correlate to find something that it is associated with Predicting success of horses: Reminiscent of Binet’s method, finds enlarged left ventricle associated with success. [but now that others know this, left ventricle will not distinguish winners from losers.] First law of viticulture Text as data; shift from United states are to united states is. / Word clouds, gender and age / Sentiment analysis of books, movies / differential language use /. [note Gentzkow and Shapiro study of 2005 congressional record] New approaches for measuring economic development including lights from space, cell phone snaps at fruitstands. Searches re Child abuse go up in recessions, but child protective services get fewer calls. (Stephens-Davidowitz 2017) References "],
["counting-and-predicting.html", "9 Counting and predicting", " 9 Counting and predicting class 1 from Salgarnik, also chapter 2 of his book: http://www.bitbybitbook.com/en/observing-behavior/ "],
["principles-of-data-visualization.html", "10 Principles of data visualization", " 10 Principles of data visualization Tufte principles tables as graphs: Gelman (2011) My bad and better vizzes Schmidt’s visualization of Rate My Professor language: http://benschmidt.org/profGender and jobs by major: http://benschmidt.org/jobs/ references for visualizations include policyviz podcast 32, data stories 110: What’s going on in this graph, and NYT edu series R4ds, Chapter 3 Kennedy Elliott 39 studies https://medium.com/@kennelliott/39-studies-about-human-perception-in-30-minutes-4728f9e31a73 https://www.youtube.com/watch?v=s0J6EDvlN30 ? References "],
["probability.html", "11 Probability", " 11 Probability See http://datasciencelabs.github.io/pages/lectures.html Stats: CLT, Hypothesis testing via simulation, Bayesian inference (https://www2.stat.duke.edu/courses/Fall15/sta112.01/) see JHU 6 inference Bayes Theorem Binomial, normal, and poisson distributions (funny image on tuna sales from economist, check dropbox) (some distributions) "],
["inference.html", "12 Inference", " 12 Inference See http://datasciencelabs.github.io/pages/lectures.html see jhu6inference.pdf law of large numbers and CLT Confidence intervals hypothesis testing multiple tests (possibly power, bootstrapping, bayesian inference) "],
["reproducibility-and-the-replication-crisis.html", "13 Reproducibility and the replication crisis", " 13 Reproducibility and the replication crisis 1. use of code rather than GUIs for data manipulation 2. use of large samples 3. use of exploratory, descriptive techniques replication crisis: https://www.nature.com/polopoly_fs/1.17412!/menu/main/topColumns/topLeftColumn/pdf/520612a.pdf discuss preregistration here introduce OSF "],
["literate-programming-with-r-markdown.html", "14 Literate programming with R markdown", " 14 Literate programming with R markdown R4DS 6 and 27 Projects in R4DS 8 https://dcl-2017-04.github.io/curriculum/rmarkdown-basics.html (r4ds-27) also possibly scripts: r4ds 6 "],
["data-visualization-in-r-with-ggplot2.html", "15 Data visualization in R with ggplot2", " 15 Data visualization in R with ggplot2 (another lecture here?) r4ds chapter 3 "],
["exploratory-data-analysis.html", "16 Exploratory Data Analysis", " 16 Exploratory Data Analysis r4ds, Chapter 3 continued - 3.4 is help and problems r4ds, chapter 7 "],
["tidy-data-and-the-tidyverse.html", "17 Tidy data and the tidyverse", " 17 Tidy data and the tidyverse r4ds 9, 10 "],
["messy-data-cleaning-and-curation.html", "18 Messy data: Cleaning and curation", " 18 Messy data: Cleaning and curation r4ds 11 getting data r4ds 12.1 12.2 Some best practices in coding and storing From hand-tally to calculator to spreadsheet Data wrangling: some problems in data https://github.com/Quartz/bad-data-guide Best practices for data in spreadsheets (Broman and Woo 2017). Code style chapter 4 r4ds Handling missing values Advantages and disadvantages of working with spreadsheets. Tidy, rectangular data allows people and computers to see data in the same way. Spreadsheets are great, but limited in some ways. They are good at showing us raw data, but not the history of how it has been transformed or analyzed. They can be cumbersome for working with large datasets, too. References "],
["selecting-data-in-r-with-dplyr.html", "19 Selecting data in R with dplyr", " 19 Selecting data in R with dplyr r4ds 5, 5.1-5.4 "],
["manipulating-data-in-r-with-dplyr.html", "20 Manipulating data in R with dplyr", " 20 Manipulating data in R with dplyr Chapter 5, sections 5.5-5.7 "],
["working-with-relational-data.html", "21 Working with relational data", " 21 Working with relational data Chapter 13 data wrangling http://www.hcbravo.org/IntroDataSci/calendar/ (SQL) Databases, SQL, join "],
["working-with-strings-factors-dates-and-times.html", "22 Working with strings, factors, dates and times", " 22 Working with strings, factors, dates and times Chapters 14-16 issues with text data, maybe silge book? "],
["working-with-lists.html", "23 Working with lists", " 23 Working with lists r4ds 20 "],
["open-science.html", "24 Open science", " 24 Open science OSF ()http://www.gastonsanchez.com/stat259/lectures/ Reproducibility and R http://ropensci.github.io/reproducibility-guide/ Baumer et al. (2014) Workflowshttp://www.gastonsanchez.com/stat259/lectures/01-introduction/ preregistration References "],
["writing-functions.html", "25 Writing functions", " 25 Writing functions "],
["writing-loops.html", "26 Writing loops", " 26 Writing loops "],
["getting-data-web-scraping-and-apis.html", "27 Getting data: Web scraping and APIs", " 27 Getting data: Web scraping and APIs web scraping and APIs (https://github.com/MUSA-620-Spring-2017) "],
["linear-and-multiple-regression.html", "28 Linear and multiple regression", " 28 Linear and multiple regression Regression and Classification, http://www.hcbravo.org/IntroDataSci/calendar/ "],
["logistic-regression.html", "29 Logistic regression", " 29 Logistic regression "],
["classification-and-types-of-errors.html", "30 Classification and types of errors", " 30 Classification and types of errors Bayes, ROC curves, measures of error. see jhu8ml "],
["cross-validation.html", "31 Cross-validation", " 31 Cross-validation "],
["some-machine-learning-techniques.html", "32 Some machine learning techniques", " 32 Some machine learning techniques Domingos (2012) References "],
["concepts-in-computational-linguistics.html", "33 Concepts in computational linguistics", " 33 Concepts in computational linguistics "],
["analyzing-text-data.html", "34 Analyzing text data", " 34 Analyzing text data danescu2013politeness (see https://github.com/jacobeisenstein/gt-css-class/blob/master/2015-files/schedule.md for lectures on networks) text analysis, LIWC "],
["from-graphs-to-networks.html", "35 From graphs to networks", " 35 From graphs to networks (see https://github.com/jacobeisenstein/gt-css-class/blob/master/2015-files/schedule.md for lectures on networks) network analysis, Gephi "],
["empirical-finsings-in-network-analysis.html", "36 Empirical finsings in network analysis", " 36 Empirical finsings in network analysis "],
["analyzing-networks.html", "37 Analyzing networks", " 37 Analyzing networks "],
["categories-and-classification.html", "38 Categories and classification", " 38 Categories and classification "],
["making-interactive-visualizations-with-r-shiny.html", "39 Making interactive visualizations with R Shiny", " 39 Making interactive visualizations with R Shiny Interactive visualizations with Shiny http://www.hcbravo.org/IntroDataSci/calendar/ "],
["the-significance-of-scalability.html", "40 The significance of scalability", " 40 The significance of scalability big data - efficient code - relative directories… "],
["digital-humanities-and-data-science.html", "41 Digital humanities and data science", " 41 Digital humanities and data science network effects vs biology in gender inequalities in diversity in tech data journalism Refs at https://github.com/sarahcnyt/stabile/blob/master/docs/bulletproof.md for readings, ideas see https://aleszu.github.io/digisoc/index.html#weekly_schedule_and_readings "],
["humility-and-teamwork.html", "42 Humility and teamwork", " 42 Humility and teamwork mesearch and my own limitations "],
["ethics-and-data-responsibility.html", "43 Ethics and data responsibility", " 43 Ethics and data responsibility http://randomwalker.info/publications/no-silver-bullet-de-identification.pdf https://github.com/jacobeisenstein/gt-css-class/blob/master/2015-files/schedule.md "],
["lab.html", "44 Lab", " 44 Lab project group at UCSB https://github.com/raviolli77/dataScience-UCSBProjectGroup-Syllabus "],
["challenges.html", "45 Challenges", " 45 Challenges maps (leaflet), googlevis, plotly, tableau, sentiment analysis see NotesonSalgarnik Lightning talks (http://www.gastonsanchez.com/stat259/labs/03-data-talks/) https://github.com/datasciencelabs/2017/blob/master/lectures/git-and-github/setting-up-github.rmd https://www.kaggle.com/competitions?segment=inClass Version control with Git https://try.github.io/levels/1/challenges/1 &amp; duke first or second class http://www.hcbravo.org/IntroDataSci/projects/Project1/ for project "],
["data-sources.html", "46 Data sources", " 46 Data sources Chetty econ/big data: http://www.equality-of-opportunity.org/bigdatacourse/ census data https://github.com/MUSA-620-Spring-2017/Course-Materials NYC taxi data http://gss.norc.org/, https://github.com/UC-MACSS/persp-analysis/blob/master/assignments/exploratory-data-analysis/README.md https://github.com/fivethirtyeight/data https://data.worldbank.org/data-catalog/world-development-indicators http://ropengov.github.io/projects/ https://grouplens.org/datasets/movielens/ Seth’s book site "],
["resources.html", "47 Resources", " 47 Resources Software carpentry (focus on code, programming, including git and R): https://software-carpentry.org/lessons/ Data carpentry and data literacy (focus on data cleaning, visualization, etc): Data carpentry for biologists http://www.datacarpentry.org/semester-biology/START-for-self-guided-students/ includes SQL other areas including genomics, ecology can be found at http://www.datacarpentry.org/lessons/ additional resource for R, text analysis, etc: https://github.com/rochelleterman/PS239T/blob/master/C_resources.md "],
["etc.html", "48 Etc 48.1 What will be in the class?", " 48 Etc 48.1 What will be in the class? R In my rough survey of introductory data science courses, I saw a pretty even split between those which begin with Python and those which begin with the statistical programming language R. This difference corresponds, loosely, to the split noted above: Computer science based approaches to data science are frequently grounded in Python, while stats based approaches are generally grounded in R. Our course, like those for most of the syllabi and courses linked above, will be based in R. Reproducible science The course will provide an introduction to some of the methods and tools of reproducible science. We will consider the replication crisis in the natural and social sciences, and then consider three distinct approaches which serve as partial solutions to the crisis. The first of these is training in a notebook-based approach to writing analyses, reports and projects (using R markdown). The second is using public repositories (such as the Open Science Framework and GitHub) to provide snapshots of projects over time. Finally, the third is to consider the place of significance testing in the age of Big Data, and to provide training in the use of descriptive, exploratory techniques of data analysis. Good visualizations Part of Type C data science is communication, and this includes not just writing up results, but also designing data displays that incisively convey the key ideas or features in a flood of data. We’ll examine and develop data visualizations such as plots, networks and text clouds. More advanced topics may include maps, interactive displays, and animations. All Some of the data It’s been argued that in the last dozen years, humans have produced more than 60 times as much information as existed in the entire previous history of humankind. (It sounds like hyperbole, but even if it’s off by an order of magnitude it’s still amazing). There are plenty of data sources for us to examine, and we’ll consider existing datasets from disciplines ranging from literature to economics to public health, with sizes ranging from a few dozen to millions of data points. We will also clean and create new datasets. All Some of the meaning Data matter, can save, enhance, or destroy human lives. (This is a crummy sentence: My pedantic insistence on treating the term “data” as plural rather than singular likely distracted you from the substance of my message. I’ll leave it here as a reminder that we can all become better writers). Back to my point: In this class, we’ll explore approaches to analyzing the meaning of data in areas including the analyses of simple texts and data journalism. All Some of the skills The skills required to extract meaning from data include an understanding of classical statistical principles (e.g., probability theory and sampling theory), core statistical techniques (regression), and the extension of these core principles and basic techniques to problems in natural language processing, the analysis of social networks, and machine learning and classification. All Some of the tools In addition to R, we’ll use a range of other tools: We’ll communicate on the Slack platform. We’ll write using markdown editors such as Typora. We’ll certainly use spreadsheets such as Excel or Google Sheets. We may use additional tools for visualizing data such as Gephi and Tableau. Hands-on computing We had initially anticipated that the lectures would include discussion, and that the computing part of the class would occur just in the lab. But, in the course of examining syllabi at other schools, it became apparent to me that there will be computing throughout the course, not just in the lab. What will be in the lab? The labs will have two features. First, they will allow for a project-based approach, focused on the collaborative analysis of problems of your own choosing. Second, these projects will include a deeper dive into some of the topics and problems above. Here are a few examples of how the treatment in the lecture and the lab are likely to differ: Topic Lecture Lab: Deeper dive Introduction Stephens-Davidowitz book; Google trends Examining one or more scholarly papers in data journalism, computational science, or computational social science Getting data Extant data Using APIs to scrape social media Sharing science Setting up account on OSF Using GitHub, Becoming a Repo Man person Exploratory data analysis / Data visualization Static data displays Interactive plots (r Shiny), animated displays?, Tableau? Sampling theory Test vs training datasets k-fold cross-validation Regression and classification Linear and logistic regression Machine learning: Robust techniques / regularized regression Supervised prediction, possibly semi-supervised and unsupervised regression Graph theory and network analysis Introduction to centrality, community structure, contagion Network robustness, different approaches to centrality &amp; community structure Analyzing texts Word clouds Text mining, natural language analysis Generating products Team project in class Project in class and poster "]
]
