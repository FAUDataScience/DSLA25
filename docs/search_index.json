[
["visualization-in-r-with-ggplot.html", "6 visualization in R with ggplot 6.1 a picture &gt; (words, numbers)? 6.2 ggplots 6.3 tracking the Novel Coronavirus 6.4 exploring more data 6.5 What’s the worst that can happen?", " 6 visualization in R with ggplot In the last chapter, we introduced data visualization, citing “vision-aries” including Edward Tufte and Hans Rosling, inspired works such as Minard’s Carte Figurative and Periscopic’s stolen years, as well as a few cautionary tales of misleading and confusing graphs. Here, in playing with and learning the R package ggplot, we begin to move from consumers to creators of data visualizations. As the first visualization in Wickham and Grolemund (2016) reminds us, data visualization is at the core of exploratory data analysis: Fig 6.1: Data visualization is at the core of data analysis (Wickham and Grolemund (2016)) In the world of data science, statistical programming is about discovering and communicating truths within your data. This exploratory data analysis is the corner of science, particularly at a time in which confirmatory studies are increasingly found to be unreproducible. Most of your reading will be from Chapter 3 of Wickham and Grolemund (2016), this is intended only as a supplement. 6.1 a picture &gt; (words, numbers)? The chapter begins with a quote from John Tukey about the importance of graphs. Yet there is a tendency among some statisticians and scientists to discount graphs, to consider graphic representations of data as less valuable than statistical ones. It is true that, because there are many ways to graph data, and because scientists and data journalists are humans with pre-existing beliefs and values, a graphical displays should not be assumed to simply depict a singular reality. But the same can be said about statistical analyses (see Chapter 8). To consider the value of statistical versus graphical displays, consider ‘Anscombe’s quartet’ (screenshot below, live at http://bit.ly/anscombe2019): Table 6.1: An adaptation of Anscombe’s “quartet” (Anscombe 1973) Exercise 6_1 Consider the spreadsheet chunk presented above, which I am characterizing as data collected on a sample of ten primary school children at recess on four consecutive days. Working with your classmates, compute the mean, standard deviation, and correlation between the two measures for one day. Share your results with the class. The four pairs of variables in Anscombe (1973) appear statistically “the same,” yet the data suggest something else. Later, we’ll try to plot these. Perhaps graphs can reveal truths that statistics can hide. 6.2 ggplots In class, we will review and recreate the plots in section 3.2 of Wickham and Grolemund (2016) and exercises through 3.4. Savor this section, reading slowly, and playing around with the RStudio interface. For example, read about the mpg data in the ‘help’ panel, pull up the mpg data in a view window, and sort through it by clicking on various columns. Fig. 6.2: A screenshot from RStudio, showing the mpg dataset 6.3 tracking the Novel Coronavirus Here, I want to consider a timely (but challenging) dataset - a live list of cases and places where cases of the novel Coronavirus, which has at this writing just been declared a public health emergency by the World Health Organization. The data are provided by the Johns Hopkins Center for Systems Science and Engineering (JHU/CSSE), and are accessed using the Googlesheets4 package written by Jenny Bryan. library(tidyverse) library(googlesheets4) library(magrittr) library(lubridate) # id for the coronavirus page (from its URL) novelCoronaID &lt;- &quot;1yZv9w9zRKwrGTaR-YzmAqMefw4wMlaXocejdxZaTs6w&quot; # number of tabs/sheets in the workbook nsheets &lt;- sheets_get(novelCoronaID) %&gt;% extract2(6) %&gt;% # gets the sixth element in a list nrow() 6.3.1 Reading the data The Novel Coronavirus data consists of a series of tabs in a Google Sheet. This finds them and combines them into a single sheet in R. Watch for a message which says that you need to authenticate this in your browser and act accordingly: # variables to retain or create numvars &lt;- c(&quot;Confirmed&quot;, &quot;Deaths&quot;, &quot;Recovered&quot;) varlist &lt;- c(&quot;Province/State&quot;, &quot;Country/Region&quot;, &quot;Last Update&quot;, numvars) # one cool trick to initialize a tibble coronaData &lt;- varlist %&gt;% map_dfr( ~tibble(!!.x := logical() ) ) # add data from Google sheet to tibble for (i in 1:nsheets) { j &lt;- read_sheet (novelCoronaID, sheet = i) # if a variable doesn&#39;t exist in sheet, add it j[setdiff(varlist,names(j))] &lt;- NA j %&lt;&gt;% select(varlist) coronaData &lt;- rbind(coronaData, j) } 6.3.2 Cleaning (wrangling, munging) the data Cleaning the data includes not just finding “errors,” but adapting it for our own use. Here, cleaning includes fixing ‘missing’ values. These were of two types - in the first few sheets, variable names were different from those on later dates, and so appear as missing. Throughout, values of NA for Deaths, Confirmed, and Recovered cases should be replaced by zero. Cleaning also includes reducing the data to the most recent value per date per place. coronaData %&lt;&gt;% mutate_if(is.numeric, ~replace_na(., 0)) %&gt;% # create a unique place variable for each row mutate(place = ifelse(is.na(`Province/State`), `Country/Region`, `Province/State`)) %&gt;% # create a new date variable and fix a missing value mutate(reportDate = ifelse(is.na(`Last Update`), ymd(&quot;2020-01-21&quot;), date(`Last Update`))) %&gt;% mutate(reportDate = as.Date(reportDate, origin = &quot;1970-01-01&quot;)) %&gt;% group_by(place,reportDate) %&gt;% # select newest report for each place and date slice(which.max(`Last Update`)) %&gt;% select(-c(place,`Last Update`)) 6.3.3 Simplifying the data: China and the rest of the world For our purposes, we can simplify the data further to just compare China with all other countries, and to reduce the data to one date for each of these two sources. coronaDataSimple &lt;- coronaData %&gt;% # three lines here for relative clarity mutate(isChina = (str_detect(`Country/Region`, &quot;China&quot;))) %&gt;% mutate(country = if_else(isChina,&quot;China&quot;,&quot;Other&quot;)) %&gt;% select(-isChina) %&gt;% # another missing case fix replace_na(list(country = &quot;China&quot;)) %&gt;% group_by(country,reportDate) %&gt;% summarize(Confirmed = sum(Confirmed), Deaths = sum(Deaths), Recovered = sum(Recovered)) %&gt;% ungroup() 6.3.4 An initial plot Here’s a first plot for you to consider and modify. ggplot(coronaDataSimple) + geom_point(aes(x=reportDate, y=Confirmed, color = country)) 6.3.5 Some questions about the coronavirus data and plots Consider the data and try to run the code yourself. What problems did you encounter? What parts need to be annotated more? Examine the plot. Are there anomalies that need to be explained? How does this data (for Confirmed) compare to the data for the other measures (Deaths and Recovered)? Plot these. What do the plots tell us? How can we edit them to learn more? Some more challenging questions. What is (roughly) the shape of the function for each of the three variables, and for China/Other? What values would you expect for, say, ten days from now? 6.4 exploring more data Explore the Gapminder data https://cran.r-project.org/web/packages/gapminder/README.html Choose one of the datasets in R, pull out a few variables, and explore these. Try to make a cool graph - one that informs the viewer, and, to paraphrase Tukey, helps us see what we don’t expect. Try several different displays. Which fail? Which succeed? Be prepared to share your efforts. Don’t be afraid to screw up. 6.5 What’s the worst that can happen? This is the worst that can happen. It probably won’t, today at least, maybe not this term. But in your fiddling, exploring, and messing around, you may tax your machine or even find a bug. Saving your work, in R as in other things, is always a good idea. Fig 6.3: Yes, R is the bomb References "]
]
