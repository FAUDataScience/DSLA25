---
title: "11-messy data"
author: "Kevin Lanning"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---
# messy data: Cleaning and curation

## status 85% {-}

The skeleton for this is great, but add one more exercise for rectangling, a link to google datasets with sample results.

---



Between 50 and 80% of the work of the data scientist consists of the compiling, cleaning and curation of data, or what is called **data wrangling**.  

One part of data wrangling is looking for and dealing with encoding inconsistencies, missing values, and errors. Consider the following:

> Exercise 11.1
>
> Run the following code in an R markdown document.  You'll need to add a library beforehand. 
>
> car2019 <- tibble("model" = c("Corolla", "Prius", "Camry", "Avalon"),
>                          "price" = c(22.5, "about 25K" , 24762, "33000-34000")) 
>
> Inspect the data frame. Add and annotate code to fix any problems that you believe exist.  Summarize the results.

Another part of data wrangling is about data rectangling [@bryan2017rectangling], that is, getting diverse types of data into a data frame (specifically, a tibble).  This is likely to be particularly challenging when you are combining data from different sources, including Web APIs (short for application programming interfaces).  We'll consider this further down the road when we talk about lists.

A third part of data wrangling is joining data from different sources. There are many ways to join datasets from different sources, but attention must be paid to insure that the observations line up correctly, that the same metrics are used for different datasets (for example, inflation adjusted dollars vs raw), that dates are interpreted as dates, that missing values are recognized as missing and not scored as zero, and so forth.  We'll talk about this in the weeks ahead, particularly when we consider relational data.

## finding data

There is no shortage of data available to analyze.  One place to start is **fivethirtyeight.com**, which includes a host of clever, clean, and largely manageable datasets which underlie the empirical analyses of Nate Silver and his team. https://data.fivethirtyeight.com/.

**Kaggle** is a noun (a community, a website, a challenge), and a verb (to kaggle is to participate in a data challenge) which describes a crowdsourced competition to improve on a problem in prediction.  Perhaps the first and best known example of this was the Netflix prize [@jackson2017netflix], which, in 2006, promised one million dollars to the first team to improve the algorithm by which that company recommended movies to its customer base. The competition took several years, and inspired substantial improvements in machine learning as well as in crowdsourced science.  At this writing, Kaggle hosts 20 active competitions - including a $1,500,000 award offered by the United States Department of Homeland Security known as the "passenger screening algorithm challenge." (Good luck!) Kaggle also hosts hundreds if not thousands of datasets. A good place to start is with their datasets stored in comma separated value format (.csv); you can find them here: https://www.kaggle.com/datasets?sortBy=published&group=public&page=1&pageSize=20&size=all&filetype=csv&license=all. 

**Reddit**, the meta-bulletin-board, includes a dataset subreddit where you may find less curated (i.e., potentially messier), topical datasets and discussions about data. Search for csv files here: https://www.reddit.com/r/datasets/search?q=csv&restrict_sr=1&sort=top.

**Github** is the primary site for coders to share and improve upon their work. Git is a system in which one can upload (*push*) one's work from a local computer to the cloud in a repository (*repo*), share this with collaborators who copy (*fork*) the repo, *pull* it down to their computers, and possibly make changes which will appear as a separate branch of the repo.  Each change is time-stamped, and efficiently stored as only its difference from the prior edit (or *commit*). There are, in all of these pushes and pulls, opportunities for collisions and problems, but learning Git remains a critical part of the data scientist's toolkit.  You can set up an account on Github if you like, but even without this you can access some of the datasets that are stored there, including a set of curated datasets on topics such as economics, demographics, air quality, flights and house prices at https://github.com/datasets/. Perhaps the easiest way to access these is to click through repos until you find a data directory, open the files up as 'raw' files, and paste them into a spreadsheet or notepad program of your choice.  Github also hosts the 'awesome public datasets' (many of which probably are) at https://github.com/awesomedata/awesome-public-datasets.  You can work with R repositories straight from R studio. 

If you are into psychology and behavioral science, the **Open Science Framework** (OSF) provides a system for hosting and sharing code and data from research articles.  One OSF page may be of particular interest, and that is a compilation of many datasets from prominent papers in psychology and psychiatry (https://osf.io/r38qu/). Incidentally, almost all of the data and code from papers I have published is on the OSF as well.

Outside of psychology, repositories of data from many disciplines may be found at **Re3data** https://www.re3data.org/. Proceed with caution - many of these datasets are likely to be quite large (for example, analyses of images) and/or in formats that for now are too challenging (JSON). Stick with data that are available in a .csv format and that don't have more than, say, a million data points (e.g., 50,000 observations * 20 variables).

Finally,  you might want to **combine multiple datasets**, such as county-level home pricing data from Zillow (https://www.zillow.com/research/data/) and county-level elections data from, for example, here: https://github.com/tonmcg/US_County_Level_Election_Results_08-16. 

In joining different datasets, or data from different sources, we can go beyond a pedagogical exercise (learning about learning) and contribute new and meaningful knowledge, e.g., "do property values go up more in blue counties when a Democrat wins the White House?" 



