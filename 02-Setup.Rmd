---
title: "02-Setup"
author: "Kevin Lanning"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---
# getting started

We begin with a brief self-assessment and a description of some rudimentary tools.

Reflect on your own knowledge of data science, including the necessary-but-not-sufficient areas of computer programming and statistics. 

## are you already a programmer and statistician?

Regarding **programming**, you may know more than you think you do.  Here's a simple program - a set of instructions - for producing a cup of coffee:

>   add water to the kettle and turn it on
>
>   if it's morning, put regular coffee in the French press, otherwise use decaf
>
>   if the water has boiled, add it to the French press, else keep waiting
>
>   if the coffee has steeped for four minutes, depress (smash) piston/plunger, else keep waiting 
>
>   pour coffee into cup
>
>   enjoy

As a post-millennial student from a WEIRD culture (a Western, Educated, Industrialized, Rich Democracy,  @henrich2010weirdest, you've 'programmed' computers, too, if only to enter a password, open an app, and upload a photo on your cell phone. 

**Statistics** is of fundamental importance, not just for understanding abstract trends, but for making decisions about everyday life. Consider the case of Susie, a college senior:

>   **Exercise 2_1** 
>   *Susie is applying to two med schools. At School A, 25% of students are accepted, and at School B, 25% are accepted as well. You are Susie. Are you going to get in to at least one of these programs?  What is the probability?  Does your estimate depend upon any assumptions?*

Questions like these are important for us. If the combined probability is low, it *likely* (another probability concept) will make sense for Susie to spend time, money, and energy to apply to additional programs. If the probability is higher, it may not. But problems like this are hard - our estimates of probability are frequently poorly calibrated, and combining probability estimates is challenging (see, e.g., @tversky1974judgment, and consider taking a course in *Behavioral Economics* or *Thinking and Decision Making* to learn more).

 You may have worked with **data** in spreadsheets such as Excel or Google Sheets.

>   **Exercise 2_2** 
>   Open the Google Sheet at http://bit.ly/dslaX2_1. Save a copy and edit it, entering the following in cell A6: 
>
>   *=SUM (A1:A5)* 
>
>   What is the result? **If you copy cell A6 to B6, what happens and why?**

In data science, spreadsheets are used largely to store data rather than to analyze it. Some *best practices* for using spreadsheets in data science are given in @broman2017data.   

## setting up your machine: some basic tools

Collaboration and communication are integral to data science. In the world beyond universities, the most important messaging and collaboration platform is **Slack.** Slack is a commercial app, but we will use the free tier. We'll use Slack for group work, class announcements, and help-seeking and help-providing. 

Slack includes a simple *markdown* editor (for 'posts').  You can find an introduction to markdown syntax in Chapter 3 of @freeman2017informatics. I use **Typora** (currently free for both Windows and Mac), but there are many alternatives. Install a Markdown editor on your laptop and play with it.

Install **R** (https://cran.rstudio.com/) then **R studio** (https://www.rstudio.com/products/rstudio/#Desktop) on your own Windows or Mac laptop.  If you get stuck, reach out to others on Slack; if you don't get stuck, help your classmates.  We'll use R studio as a front end (an 'integrated development environment', or IDE) for R, and will write most of our code in R markdown which is, not surprisingly, a 'flavor' of markdown. We'll go into R in increasing depth beginning in the next chapter; if you want to get a head start, consider [Carmichael (2017) Getting started](https://idc9.github.io/stor390/notes/getting_started/getting_started.html) and the first chapter of @wickham2016r. (Those documents, like this one, are all written in R markdown).  

Finally, **Google Docs** is free and is convenient for collaborative work. One other important feature of Google Docs is that it provides a framework for *version control,* a critical skill in information management. You can learn more about how to see and revert to prior versions of a project in Google Docs [here](https://sites.google.com/site/scriptsexamples/home/announcements/named-versions-new-version-history-google-docs).  

Version control can help you avoid the chaos and confusion of having a computer (or several computers) full of files that look like Cham's (2012) comic:     

![*Fig 2.1: Never call anything 'final.doc'.*](final.jpg)

We'll be talking about the challenge of version control throughout this text - and I am hoping that my own habits in file management can improve as we move forward together.

##  discussion: who deserves a good grade?

In an introductory class in data science, students invariably come to class with different backgrounds.  Should this be taken into account in assigning grades? That is, would it be possible (and desirable) to assign grades in a class based not just on what students know at the end of the term, but also on how much they have learned?  

A formal, statistical approach to this could use regression analysis.  That is, one could predict final exam scores from pretest scores, and use the residuals - the extent to which students did better or worse than expected - as a contributor to final exam grades. Interestingly, there would be an unusual incentive for students on this 'pretest' to do, seemingly perversely, as poorly as possible.  How could this be addressed?

Another problem with this approach is that there may be 'ceiling effects' - students who are the strongest coming in to the class can't improve as much as those who have more room to grow.  Again, how might this be addressed?